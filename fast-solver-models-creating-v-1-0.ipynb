{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Две модели с крутыми гиперпараметрами для ансамбля.\n\n# LGBMRegressor с такими гиперпараметрами на данных (2 кодированных 32-размерных хэша + 768-размерные эмбеддинги) имеет почти такой же результат, как и CatBoostRegressor.\n```python\n# предполагается, что есть x_train, y_train, x_test и y_test.\n\nmodel1 = LGBMRegressor(\n    metric='mape',  # поменять под метрику, которая используется для оценки сабмита\n    n_estimators=30000,\n    learning_rate=0.01,\n    feature_fraction=0.8,\n    bagging_fraction=0.8,\n    bagging_freq=1,\n    lambda_l1=0.1,\n    lambda_l2=0.1,\n    num_leaves=64,\n    verbose=-1,\n    seed=42\n)\nmodel1.fit(\n    x_train, y_train,\n    eval_set=[(x_test, y_test)],\n    callbacks=[\n        lgb.early_stopping(1500),\n        lgb.log_evaluation(period=500)\n    ]\n)\n\nmodel2 = CatBoostRegressor(\n    iterations=20000,\n    depth=10,\n    learning_rate=0.02,\n    l2_leaf_reg=5.0,\n    early_stopping_rounds=1000,\n    cat_features=categorical_columns,\n    eval_metric='MAPE',  # поменять под метрику, которая используется для оценки сабмита\n    verbose=200,\n    task_type='GPU',\n    random_state=42\n)\nmodel2.fit(x_train, y_train, eval_set=(x_test, y_test))\n\n# потом результаты этих моделей просто усредняются\n```","metadata":{}}]}