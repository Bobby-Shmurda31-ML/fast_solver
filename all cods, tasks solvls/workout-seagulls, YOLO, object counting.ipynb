{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e6c925",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-09-16T04:37:34.429111Z",
     "iopub.status.busy": "2025-09-16T04:37:34.428807Z",
     "iopub.status.idle": "2025-09-16T04:38:52.971278Z",
     "shell.execute_reply": "2025-09-16T04:38:52.970273Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 78.54879,
     "end_time": "2025-09-16T04:38:52.972831",
     "exception": false,
     "start_time": "2025-09-16T04:37:34.424041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.200-py3-none-any.whl.metadata (37 kB)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\r\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Downloading ultralytics-8.3.200-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\r\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.200 ultralytics-thop-2.0.17\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dfdf8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T04:38:53.014302Z",
     "iopub.status.busy": "2025-09-16T04:38:53.013592Z",
     "iopub.status.idle": "2025-09-16T04:39:02.780043Z",
     "shell.execute_reply": "2025-09-16T04:39:02.779347Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 9.788641,
     "end_time": "2025-09-16T04:39:02.781460",
     "exception": false,
     "start_time": "2025-09-16T04:38:52.992819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.200)\r\n",
      "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\r\n",
      "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\r\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.17)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import tempfile\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.downloads import attempt_download_asset\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "class YOLODetectionPipeline:\n",
    "    \"\"\"\n",
    "    YOLO-пайплайн из pandas DataFrame с опциональным подбором гиперпараметров для подсчёта объектов\n",
    "    и калибровкой линейной моделью (Ridge).\n",
    "\n",
    "    Данные:\n",
    "      train_df/val_df — DataFrame с колонками:\n",
    "        - image_path (str): путь к изображению (jpg/png)\n",
    "        - boxes_col (list[list[float]]): список боксов [[x,y,w,h], ...] в YOLO-нормировке [0..1]\n",
    "\n",
    "    Основной сценарий:\n",
    "      - fit(): обучает YOLO; (опц.) подбирает conf/iou/max_det; (опц.) обучает Ridge по фичам детектора;\n",
    "               (опц.) печатает RMSE/MAE для plain count и calibrated count.\n",
    "      - predict(): возвращает детекции (boxes_json + count). Калибровка тут НЕ применяется.\n",
    "      - predict_counts(): возвращает числовой подсчёт. Если включена и обучена калибровка — применит Ridge,\n",
    "                          иначе вернёт plain len(detections), использовав лучшие найденные пороги (если тюнинг включён).\n",
    "\n",
    "    Устройство:\n",
    "      - device в fit/predict/predict_counts можно не указывать — сработает авто:\n",
    "            \"0,1,...,N-1\" для train (если доступно N GPUs) → внутри пайплайна\n",
    "            инференс/тюнинг выполняются на первой карте \"0\" (устойчивее),\n",
    "            иначе — \"cpu\".\n",
    "      - Можно передать device=\"0\" или \"cpu\" явно — приоритет выше авто.\n",
    "\n",
    "    Время тюнинга:\n",
    "      - tune_val_subsample: подвыборка валидации (int — кол-во, float — доля 0..1).\n",
    "      - tune_max_combinations: лимит числа комбинаций из сетки (conf×iou×max_det).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_ckpt: str = \"yolov8n.pt\",\n",
    "                 data_root: str | None = None,\n",
    "                 image_col: str = \"image_path\",\n",
    "                 boxes_col: str = \"boxes\",\n",
    "                 class_names: list[str] | None = None,\n",
    "                 use_symlinks: bool = True,\n",
    "                 verbose: bool = True,\n",
    "                 # переключатели\n",
    "                 enable_tuning: bool = True,\n",
    "                 enable_ridge: bool = True,\n",
    "                 validate_count: bool = True,\n",
    "                 # управление временем тюнинга\n",
    "                 tune_val_subsample: int | float | None = None,  # int=кол-во картинок; float=доля [0..1]\n",
    "                 tune_max_combinations: int | None = None,       # ограничение числа комбо (случайно из сетки)\n",
    "                 random_state: int = 42,\n",
    "                 # сетки для тюнинга\n",
    "                 tune_conf_grid = np.linspace(0.05, 0.6, 12),\n",
    "                 tune_iou_grid  = (0.4, 0.5, 0.6),\n",
    "                 tune_max_det_grid = (300, 1000, 2000),\n",
    "                 ridge_alpha_grid = (0.1, 0.3, 1.0, 2.0, 3.0, 5.0),\n",
    "                 # пороги нормированной площади для фич:\n",
    "                 small_thr: float = 0.005,\n",
    "                 big_thr: float   = 0.05):\n",
    "        self.model_ckpt = model_ckpt\n",
    "        self.image_col = image_col\n",
    "        self.boxes_col = boxes_col\n",
    "        self.class_names = class_names or [\"obj\"]\n",
    "        self.use_symlinks = use_symlinks\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.enable_tuning = enable_tuning\n",
    "        self.enable_ridge = enable_ridge\n",
    "        self.validate_count = validate_count\n",
    "        self.tune_val_subsample = tune_val_subsample\n",
    "        self.tune_max_combinations = tune_max_combinations\n",
    "        self.random_state = random_state\n",
    "\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        # рабочая папка\n",
    "        self._tmpdir_owned = False\n",
    "        if data_root is None:\n",
    "            self.data_root = tempfile.mkdtemp(prefix=\"yolo_ds_\")\n",
    "            self._tmpdir_owned = True\n",
    "        else:\n",
    "            self.data_root = os.path.abspath(data_root)\n",
    "            os.makedirs(self.data_root, exist_ok=True)\n",
    "\n",
    "        self.dataset_yaml = os.path.join(self.data_root, \"dataset.yaml\")\n",
    "        self.model_path = None\n",
    "        self._model = None\n",
    "        self._device = None  # устройство, использованное при fit()\n",
    "\n",
    "        # сетки и пороги фич\n",
    "        self.tune_conf_grid = np.array(tune_conf_grid, dtype=float)\n",
    "        self.tune_iou_grid  = tuple(tune_iou_grid)\n",
    "        self.tune_max_det_grid = tuple(int(x) for x in tune_max_det_grid)\n",
    "        self.ridge_alpha_grid = tuple(float(x) for x in ridge_alpha_grid)\n",
    "        self.small_thr = float(small_thr)\n",
    "        self.big_thr   = float(big_thr)\n",
    "\n",
    "        # сохранённые результаты тюнинга/калибровки\n",
    "        self.calib_ = dict(\n",
    "            best_conf=None, best_iou=None, best_max_det=None,\n",
    "            ridge_alpha=None, ridge_model=None,\n",
    "            imgsz=None\n",
    "        )\n",
    "\n",
    "    # -------------------- device helpers --------------------\n",
    "    @staticmethod\n",
    "    def _resolve_device(device: str | int | None) -> str:\n",
    "        \"\"\"\n",
    "        Преобразует device для Ultralytics:\n",
    "          - None или \"auto\": если есть CUDA → \"0,1,...,N-1\" для train; иначе \"cpu\"\n",
    "          - иначе возвращает str(device)\n",
    "        Используется в fit() для обучения.\n",
    "        \"\"\"\n",
    "        if device is None or str(device).lower() == \"auto\":\n",
    "            if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "                n = torch.cuda.device_count()\n",
    "                return \",\".join(str(i) for i in range(n))  # напр. \"0\" или \"0,1\"\n",
    "            return \"cpu\"\n",
    "        return str(device)\n",
    "\n",
    "    def _infer_device(self) -> str:\n",
    "        \"\"\"\n",
    "        Устройство для инференса/тюнинга:\n",
    "          - если тренировались на '0,1,...' → берём первую карту '0'\n",
    "          - если тренировались на одной карте 'k' → её же\n",
    "          - иначе авто: '0' при наличии CUDA, 'cpu' без GPU\n",
    "        \"\"\"\n",
    "        if getattr(self, \"_device\", None):\n",
    "            if isinstance(self._device, str) and \",\" in self._device:\n",
    "                return self._device.split(\",\")[0]\n",
    "            return self._device\n",
    "        return \"0\" if (torch.cuda.is_available() and torch.cuda.device_count() > 0) else \"cpu\"\n",
    "\n",
    "    # -------------------- helpers: разметка → YOLO-тxt --------------------\n",
    "    @staticmethod\n",
    "    def _is_nan_like(x):\n",
    "        if x is None: return True\n",
    "        if isinstance(x, float) and np.isnan(x): return True\n",
    "        if isinstance(x, str) and x.strip()==\"\": return True\n",
    "        return False\n",
    "\n",
    "    def _parse_boxes(self, row):\n",
    "        boxes_raw = row[self.boxes_col] if self.boxes_col in row else None\n",
    "        if self._is_nan_like(boxes_raw): return []\n",
    "        out = []\n",
    "        if isinstance(boxes_raw, (list, tuple, np.ndarray)):\n",
    "            for it in boxes_raw:\n",
    "                vals = list(map(float, it))\n",
    "                if len(vals) >= 4:\n",
    "                    x,y,w,h = vals[:4]\n",
    "                    if 0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1:\n",
    "                        out.append((0, x,y,w,h))\n",
    "        elif isinstance(boxes_raw, str):\n",
    "            lines = [ln.strip() for ln in boxes_raw.strip().splitlines() if ln.strip()]\n",
    "            for ln in lines:\n",
    "                parts = ln.split()\n",
    "                vals = list(map(float, parts))\n",
    "                if len(vals) == 4:\n",
    "                    x,y,w,h = vals\n",
    "                    out.append((0, x,y,w,h))\n",
    "                elif len(vals) >= 5:\n",
    "                    cls,x,y,w,h = int(vals[0]), *vals[1:5]\n",
    "                    out.append((cls, float(x),float(y),float(w),float(h)))\n",
    "        return out\n",
    "\n",
    "    def _link_or_copy(self, src, dst):\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        if self.use_symlinks:\n",
    "            try:\n",
    "                if os.path.lexists(dst): os.remove(dst)\n",
    "                os.symlink(os.path.abspath(src), dst)\n",
    "                return\n",
    "            except Exception:\n",
    "                pass\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    def _write_label_file(self, label_path, boxes):\n",
    "        os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
    "        with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for cls, x,y,w,h in boxes:\n",
    "                f.write(f\"{int(cls)} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    def _materialize(self, train_df, val_df, train_split=\"train\", val_split=\"val\"):\n",
    "        for split_name, df in [(train_split, train_df), (val_split, val_df)]:\n",
    "            img_dir = os.path.join(self.data_root, \"images\", split_name)\n",
    "            lbl_dir = os.path.join(self.data_root, \"labels\", split_name)\n",
    "            os.makedirs(img_dir, exist_ok=True); os.makedirs(lbl_dir, exist_ok=True)\n",
    "            it = df.iterrows()\n",
    "            if self.verbose: it = tqdm(it, total=len(df), desc=f\"[build] {split_name}\")\n",
    "            for _, row in it:\n",
    "                src = row[self.image_col]\n",
    "                if not os.path.exists(src):\n",
    "                    raise FileNotFoundError(f\"Image not found: {src}\")\n",
    "                fname = os.path.basename(src)\n",
    "                stem, _ = os.path.splitext(fname)\n",
    "                self._link_or_copy(src, os.path.join(img_dir, fname))\n",
    "                self._write_label_file(os.path.join(lbl_dir, stem + \".txt\"), self._parse_boxes(row))\n",
    "\n",
    "        with open(self.dataset_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"path: {self.data_root}\\ntrain: images/{train_split}\\nval: images/{val_split}\\nnames:\\n\")\n",
    "            for i, name in enumerate(self.class_names):\n",
    "                f.write(f\"  {i}: {name}\\n\")\n",
    "\n",
    "    # -------------------- fit: train + (tune/ridge/validate) --------------------\n",
    "    def fit(self,\n",
    "            train_df: pd.DataFrame,\n",
    "            val_df: pd.DataFrame | None = None,\n",
    "            test_size: float = 0.2,\n",
    "            epochs: int = 50,\n",
    "            imgsz: int = 640,\n",
    "            batch: int = 16,\n",
    "            device: str | int | None = \"auto\",\n",
    "            workers: int = 4,\n",
    "            patience: int = 50,\n",
    "            optimizer: str = \"auto\",\n",
    "            augment: bool = True,\n",
    "            seed: int = 42,\n",
    "            close_mosaic: int | None = 10,\n",
    "            cos_lr: bool = True,\n",
    "            rect: bool = False,\n",
    "            iou: float = 0.7,\n",
    "            **extra_train_kwargs):\n",
    "\n",
    "        # выбрать устройство для тренировки и сохранить\n",
    "        self._device = self._resolve_device(device)\n",
    "        if self.verbose:\n",
    "            print(f\"[device] training device='{self._device}'\")\n",
    "\n",
    "        np.random.seed(seed); random.seed(seed)\n",
    "\n",
    "        # если val_df не задан — сделаем стратифицированный сплит по бинам count\n",
    "        if val_df is None:\n",
    "            tmp = train_df.copy()\n",
    "            counts = [len(self._parse_boxes(r)) for _, r in tmp.iterrows()]\n",
    "            tmp[\"_bins\"] = np.clip((np.array(counts)//5).astype(int), 0, 50)\n",
    "            val_mask = tmp.groupby(\"_bins\", group_keys=False).apply(\n",
    "                lambda g: g.sample(frac=test_size, random_state=seed)).index\n",
    "            val_df = train_df.loc[val_mask]\n",
    "            train_df = train_df.drop(index=val_mask)\n",
    "            train_df = train_df.reset_index(drop=True); val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "        # собрать датасет на диск\n",
    "        self._materialize(train_df, val_df)\n",
    "\n",
    "        # загрузить/скачать чекпоинт при необходимости\n",
    "        if not os.path.exists(self.model_ckpt) and self.model_ckpt.endswith(\".pt\"):\n",
    "            try:\n",
    "                if self.verbose: print(f\"Checkpoint '{self.model_ckpt}' not found. Attempting to download...\")\n",
    "                attempt_download_asset(self.model_ckpt)\n",
    "            except Exception as e:\n",
    "                raise FileNotFoundError(f\"Failed to download '{self.model_ckpt}'. Error: {e}\")\n",
    "\n",
    "        # train args\n",
    "        train_args = {\n",
    "            'data': self.dataset_yaml, 'epochs': epochs, 'imgsz': imgsz, 'batch': batch,\n",
    "            'device': self._device, 'workers': workers, 'patience': patience, 'optimizer': optimizer,\n",
    "            'augment': augment, 'seed': seed, 'close_mosaic': close_mosaic, 'cos_lr': cos_lr,\n",
    "            'rect': rect, 'iou': iou, 'verbose': self.verbose\n",
    "        }\n",
    "        train_args.update(extra_train_kwargs)\n",
    "\n",
    "        # обучение\n",
    "        model = YOLO(self.model_ckpt)\n",
    "        model.train(**train_args)\n",
    "        \n",
    "        # NEW: корректно выбираем путь к лучшим весам\n",
    "        best_path = None\n",
    "        # Ultralytics v8: после train лучший чекпоинт лежит в model.trainer.best\n",
    "        if hasattr(model, \"trainer\") and getattr(model.trainer, \"best\", None):\n",
    "            best_path = str(model.trainer.best)  # .../runs/detect/exp/weights/best.pt\n",
    "        # запасной вариант (иногда ckpt_path есть, но в новых релизах — нет)\n",
    "        elif getattr(model, \"ckpt_path\", None):\n",
    "            best_path = str(model.ckpt_path)\n",
    "        # если по какой-то причине не нашли best/last — используем исходный чекпоинт\n",
    "        else:\n",
    "            best_path = self.model_ckpt\n",
    "        \n",
    "        self.model_path = best_path\n",
    "        if self.verbose:\n",
    "            print(f\"[fit] best model: {self.model_path}\")\n",
    "\n",
    "        # тюнинг/калибровка/валидация\n",
    "        try:\n",
    "            self._tune_and_or_calibrate(val_df, imgsz=imgsz)\n",
    "            if self.validate_count:\n",
    "                self._validate_counting(val_df)\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"[post-fit] skipped tuning/calibration/validation due to: {e}\")\n",
    "\n",
    "        return self.model_path\n",
    "\n",
    "    # -------------------- инференс-хелперы --------------------\n",
    "    def _ensure_model(self):\n",
    "        if self._model is None:\n",
    "            path = self.model_path or self.model_ckpt\n",
    "            self._model = YOLO(path)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _raw_counts(self, paths, imgsz, conf, iou, max_det):\n",
    "        self._ensure_model()\n",
    "        out = []\n",
    "        dev = self._infer_device()  # ВСЕГДА одна карта при инференсе/тюнинге\n",
    "        for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[counts]\"):\n",
    "            batch = paths[i:i+64]\n",
    "            res = self._model.predict(batch, imgsz=imgsz, conf=conf, iou=iou,\n",
    "                                      max_det=max_det, device=dev, verbose=False)\n",
    "            for r in res:\n",
    "                out.append(int(len(r.boxes) if (r.boxes is not None) else 0))\n",
    "        return np.array(out, dtype=float)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _yolo_feats(self, paths, imgsz, conf, iou, max_det):\n",
    "        self._ensure_model()\n",
    "        rows = []\n",
    "        dev = self._infer_device()\n",
    "        for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[feats]\"):\n",
    "            batch = paths[i:i+64]\n",
    "            res = self._model.predict(batch, imgsz=imgsz, conf=conf, iou=iou,\n",
    "                                      max_det=max_det, device=dev, verbose=False)\n",
    "            for r in res:\n",
    "                if r.boxes is None or len(r.boxes) == 0:\n",
    "                    rows.append(dict(n=0, conf_sum=0, conf_mean=0, conf_max=0,\n",
    "                                     area_mean=0, frac_small=0, frac_mid=0, frac_big=0))\n",
    "                    continue\n",
    "                confs = r.boxes.conf.cpu().numpy()\n",
    "                xywhn = r.boxes.xywhn.cpu().numpy()\n",
    "                areas = (xywhn[:,2] * xywhn[:,3]).clip(0, 1)\n",
    "                rows.append(dict(\n",
    "                    n=len(confs),\n",
    "                    conf_sum=float(confs.sum()),\n",
    "                    conf_mean=float(confs.mean()),\n",
    "                    conf_max=float(confs.max()),\n",
    "                    area_mean=float(areas.mean()),\n",
    "                    frac_small=float((areas < self.small_thr).mean()),\n",
    "                    frac_mid=float(((areas >= self.small_thr) & (areas <= self.big_thr)).mean()),\n",
    "                    frac_big=float((areas > self.big_thr).mean())\n",
    "                ))\n",
    "        return pd.DataFrame(rows).to_numpy()\n",
    "\n",
    "    # -------------------- подвыборка валидации --------------------\n",
    "    def _subset_val(self, val_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.tune_val_subsample is None:\n",
    "            return val_df\n",
    "        n = len(val_df)\n",
    "        if isinstance(self.tune_val_subsample, float):\n",
    "            k = max(1, int(round(n * self.tune_val_subsample)))\n",
    "        else:\n",
    "            k = int(self.tune_val_subsample)\n",
    "        k = min(k, n)\n",
    "        return val_df.sample(n=k, random_state=self.random_state).reset_index(drop=True)\n",
    "\n",
    "    # -------------------- тюнинг и/или калибровка --------------------\n",
    "    def _tune_and_or_calibrate(self, val_df: pd.DataFrame, imgsz: int):\n",
    "        val_sub = self._subset_val(val_df)\n",
    "        paths = val_sub[self.image_col].tolist()\n",
    "        y_true = np.array([len(self._parse_boxes(r)) for _, r in val_sub.iterrows()], dtype=float)\n",
    "\n",
    "        best_conf, best_iou, best_max_det = None, None, None\n",
    "\n",
    "        # 1) тюнинг plain count (если включён)\n",
    "        if self.enable_tuning:\n",
    "            combos = [(float(c), float(i), int(m))\n",
    "                      for i in self.tune_iou_grid\n",
    "                      for m in self.tune_max_det_grid\n",
    "                      for c in self.tune_conf_grid]\n",
    "            random.shuffle(combos)\n",
    "            if self.tune_max_combinations is not None:\n",
    "                combos = combos[:int(self.tune_max_combinations)]\n",
    "\n",
    "            best_rmse = 1e9\n",
    "            for conf, iou, max_det in combos:\n",
    "                y_pred = self._raw_counts(paths, imgsz=imgsz, conf=conf, iou=iou, max_det=max_det)\n",
    "                rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse, best_conf, best_iou, best_max_det = rmse, conf, iou, max_det\n",
    "            if self.verbose:\n",
    "                print(f\"[tune] best plain count: conf={best_conf}, iou={best_iou}, max_det={best_max_det}  RMSE={best_rmse:.3f}\")\n",
    "        else:\n",
    "            best_conf, best_iou, best_max_det = 0.25, 0.5, 1000\n",
    "            if self.verbose:\n",
    "                print(\"[tune] disabled → using defaults conf=0.25, iou=0.5, max_det=1000\")\n",
    "\n",
    "        # 2) калибровка Ridge (если включена)\n",
    "        ridge_model, ridge_alpha = None, None\n",
    "        if self.enable_ridge:\n",
    "            X = self._yolo_feats(paths, imgsz=imgsz, conf=best_conf, iou=best_iou, max_det=best_max_det)\n",
    "            best_rmse = 1e9\n",
    "            for a in self.ridge_alpha_grid:\n",
    "                m = Ridge(alpha=float(a)).fit(X, y_true)\n",
    "                y_hat = m.predict(X)\n",
    "                rmse = mean_squared_error(y_true, y_hat, squared=False)\n",
    "                if rmse < best_rmse:\n",
    "                    best_rmse, ridge_alpha, ridge_model = rmse, float(a), m\n",
    "            if self.verbose:\n",
    "                print(f\"[calib] Ridge alpha={ridge_alpha}  RMSE(calib)={best_rmse:.3f}\")\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(\"[calib] Ridge disabled\")\n",
    "\n",
    "        # сохранить найденное\n",
    "        self.calib_.update(dict(\n",
    "            best_conf=best_conf if self.enable_tuning else None,\n",
    "            best_iou=best_iou if self.enable_tuning else None,\n",
    "            best_max_det=best_max_det if self.enable_tuning else None,\n",
    "            ridge_alpha=ridge_alpha if self.enable_ridge else None,\n",
    "            ridge_model=ridge_model if self.enable_ridge else None,\n",
    "            imgsz=imgsz\n",
    "        ))\n",
    "\n",
    "    # -------------------- финальная валидация подсчёта --------------------\n",
    "    def _validate_counting(self, val_df: pd.DataFrame):\n",
    "        paths = val_df[self.image_col].tolist()\n",
    "        y_true = np.array([len(self._parse_boxes(r)) for _, r in val_df.iterrows()], dtype=float)\n",
    "\n",
    "        imgsz = self.calib_['imgsz'] or 640\n",
    "        conf  = self.calib_['best_conf'] if self.enable_tuning else 0.25\n",
    "        iou   = self.calib_['best_iou']  if self.enable_tuning else 0.5\n",
    "        max_det = self.calib_['best_max_det'] if self.enable_tuning else 1000\n",
    "\n",
    "        y_plain = self._raw_counts(paths, imgsz, conf, iou, max_det)\n",
    "        rmse_plain = mean_squared_error(y_true, y_plain, squared=False)\n",
    "        mae_plain  = mean_absolute_error(y_true, y_plain)\n",
    "\n",
    "        if self.enable_ridge and self.calib_['ridge_model'] is not None:\n",
    "            X = self._yolo_feats(paths, imgsz, conf, iou, max_det)\n",
    "            y_cal = np.clip(self.calib_['ridge_model'].predict(X), 0, None)\n",
    "            rmse_cal = mean_squared_error(y_true, y_cal, squared=False)\n",
    "            mae_cal  = mean_absolute_error(y_true, y_cal)\n",
    "            print(f\"[val-count] plain: RMSE={rmse_plain:.3f}, MAE={mae_plain:.3f}  |  calibrated: RMSE={rmse_cal:.3f}, MAE={mae_cal:.3f}\")\n",
    "        else:\n",
    "            print(f\"[val-count] plain: RMSE={rmse_plain:.3f}, MAE={mae_plain:.3f}  |  calibrated: (disabled)\")\n",
    "\n",
    "    # -------------------- публичный инференс: детекции --------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, df: pd.DataFrame,\n",
    "                conf: float = 0.25, iou: float = 0.6,\n",
    "                imgsz: int = 640, device: str | int | None = \"auto\",\n",
    "                max_det: int = 300, agnostic_nms: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Детекции (калибровка НЕ используется).\"\"\"\n",
    "        assert self.image_col in df.columns\n",
    "        if self._model is None:\n",
    "            self._model = YOLO(self.model_path or self.model_ckpt)\n",
    "\n",
    "        # для инференса в ноутбуках мульти-GPU может быть нестабилен — оставляем одну карту\n",
    "        dev = self._resolve_device(device if device is not None else self._infer_device())\n",
    "\n",
    "        paths = df[self.image_col].tolist()\n",
    "        preds = []\n",
    "        for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[predict]\"):\n",
    "            batch = paths[i:i+64]\n",
    "            res = self._model(batch, conf=conf, iou=iou, imgsz=imgsz,\n",
    "                              device=dev, verbose=False, max_det=max_det,\n",
    "                              agnostic_nms=agnostic_nms)\n",
    "            for r in res:\n",
    "                boxes = []\n",
    "                if r.boxes is not None and len(r.boxes):\n",
    "                    xywhn = r.boxes.xywhn.cpu().numpy()\n",
    "                    confv = r.boxes.conf.cpu().numpy()\n",
    "                    clsv  = r.boxes.cls.cpu().numpy().astype(int)\n",
    "                    for (x,y,w,h), c, k in zip(xywhn, confv, clsv):\n",
    "                        boxes.append({\"cls\": int(k), \"conf\": float(c),\n",
    "                                      \"x\": float(x), \"y\": float(y), \"w\": float(w), \"h\": float(h)})\n",
    "                preds.append({\n",
    "                    self.image_col: r.path,\n",
    "                    \"count\": len(boxes),\n",
    "                    \"boxes_json\": json.dumps(boxes, ensure_ascii=False)\n",
    "                })\n",
    "        return pd.DataFrame(preds)\n",
    "\n",
    "    # -------------------- публичный инференс: подсчёт --------------------\n",
    "    @torch.no_grad()\n",
    "    def predict_counts(self, df: pd.DataFrame,\n",
    "                       imgsz: int | None = None,\n",
    "                       conf: float | None = None,\n",
    "                       iou: float | None = None,\n",
    "                       max_det: int | None = None,\n",
    "                       device: str | int | None = \"auto\",\n",
    "                       clamp_nonneg: bool = True,\n",
    "                       do_round: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Подсчёт объектов.\n",
    "          - Если enable_ridge=True и калибратор обучен → применяет Ridge (на лучших conf/iou/max_det при enable_tuning).\n",
    "          - Иначе → plain len(detections) с conf/iou/max_det:\n",
    "              * если enable_tuning=True → используем лучшие найденные;\n",
    "              * если enable_tuning=False → дефолты conf=0.25, iou=0.5, max_det=1000.\n",
    "        \"\"\"\n",
    "        assert self.image_col in df.columns\n",
    "        if self._model is None:\n",
    "            self._model = YOLO(self.model_path or self.model_ckpt)\n",
    "\n",
    "        dev = self._resolve_device(device if device is not None else self._infer_device())\n",
    "\n",
    "        imgsz = imgsz or self.calib_['imgsz'] or 640\n",
    "        if self.enable_tuning and self.calib_['best_conf'] is not None:\n",
    "            conf_def, iou_def, max_det_def = self.calib_['best_conf'], self.calib_['best_iou'], self.calib_['best_max_det']\n",
    "        else:\n",
    "            conf_def, iou_def, max_det_def = 0.25, 0.5, 1000\n",
    "\n",
    "        use_conf  = conf    if conf    is not None else conf_def\n",
    "        use_iou   = iou     if iou     is not None else iou_def\n",
    "        use_maxdet= max_det if max_det is not None else max_det_def\n",
    "\n",
    "        paths = df[self.image_col].tolist()\n",
    "\n",
    "        # калиброванный вариант\n",
    "        if self.enable_ridge and self.calib_['ridge_model'] is not None:\n",
    "            # считаем фичи на одной карте\n",
    "            X = []\n",
    "            for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[feats]\"):\n",
    "                batch = paths[i:i+64]\n",
    "                res = self._model.predict(batch, imgsz=imgsz, conf=use_conf, iou=use_iou,\n",
    "                                          max_det=use_maxdet, device=dev, verbose=False)\n",
    "                for r in res:\n",
    "                    if r.boxes is None or len(r.boxes) == 0:\n",
    "                        X.append([0,0,0,0,0,0,0,0]); continue\n",
    "                    confs = r.boxes.conf.cpu().numpy()\n",
    "                    xywhn = r.boxes.xywhn.cpu().numpy()\n",
    "                    areas = (xywhn[:,2]*xywhn[:,3]).clip(0,1)\n",
    "                    X.append([\n",
    "                        len(confs), float(confs.sum()), float(confs.mean()), float(confs.max()),\n",
    "                        float(areas.mean()),\n",
    "                        float((areas < self.small_thr).mean()),\n",
    "                        float(((areas >= self.small_thr) & (areas <= self.big_thr)).mean()),\n",
    "                        float((areas > self.big_thr).mean())\n",
    "                    ])\n",
    "            y = self.calib_['ridge_model'].predict(np.asarray(X, dtype=float))\n",
    "        else:\n",
    "            # plain len(det) на одной карте\n",
    "            y = []\n",
    "            for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[counts]\"):\n",
    "                batch = paths[i:i+64]\n",
    "                res = self._model.predict(batch, imgsz=imgsz, conf=use_conf, iou=use_iou,\n",
    "                                          max_det=use_maxdet, device=dev, verbose=False)\n",
    "                for r in res:\n",
    "                    y.append(int(len(r.boxes) if (r.boxes is not None) else 0))\n",
    "            y = np.asarray(y, dtype=float)\n",
    "\n",
    "        if clamp_nonneg: y = np.clip(y, 0, None)\n",
    "        if do_round:     y = np.rint(y)\n",
    "\n",
    "        out = df[[self.image_col]].copy()\n",
    "        out[\"label\"] = y\n",
    "        return out\n",
    "\n",
    "    # -------------------- housekeeping --------------------\n",
    "    def cleanup(self):\n",
    "        if self._tmpdir_owned and os.path.isdir(self.data_root):\n",
    "            shutil.rmtree(self.data_root, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52326e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T04:39:02.832845Z",
     "iopub.status.busy": "2025-09-16T04:39:02.832439Z",
     "iopub.status.idle": "2025-09-16T04:39:02.922427Z",
     "shell.execute_reply": "2025-09-16T04:39:02.921757Z"
    },
    "papermill": {
     "duration": 0.117296,
     "end_time": "2025-09-16T04:39:02.923802",
     "exception": false,
     "start_time": "2025-09-16T04:39:02.806506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yolo_detection_pipeline.py\n",
    "# Обновлённый пайплайн:\n",
    "# - авто-выбор устройства (GPU '0' / мульти-GPU '0,1,...' / CPU),\n",
    "# - тюнинг подсчёта: plain (conf/iou/max_det) ИЛИ area-gated (cs/cb/area_thr + iou/max_det),\n",
    "# - Ridge-калибровка по резидуалу (K-fold CV, стандартизация),\n",
    "# - устойчивый инференс при мульти-GPU (тюнинг/инференс на первой карте),\n",
    "# - финальная валидация RMSE/MAE для задачи подсчёта.\n",
    "#\n",
    "# Требования:\n",
    "# pip install -U ultralytics opencv-python pandas numpy scikit-learn tqdm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.downloads import attempt_download_asset\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class YOLODetectionPipeline:\n",
    "    \"\"\"\n",
    "    YOLO-пайплайн из pandas DataFrame с опциональным подбором гиперпараметров подсчёта\n",
    "    (plain или area-gated) и калибровкой линейной моделью (Ridge по резидуалу).\n",
    "\n",
    "    Входные данные (DataFrame):\n",
    "      - image_path (str): путь к изображению (jpg/png)\n",
    "      - boxes_col: GT-боксы в YOLO-нормировке [0..1] (списки/массивы/строка)\n",
    "\n",
    "    Основной сценарий:\n",
    "      - fit(): обучает YOLO; (опц.) тюнинг порогов (plain/area-gated + iou/max_det);\n",
    "               (опц.) калибрует Ridge; (опц.) валидирует RMSE/MAE.\n",
    "      - predict(): возвращает детекции (boxes_json + count). Калибровка НЕ применяется.\n",
    "      - predict_counts(): возвращает числовой подсчёт; применяет лучшие пороги/калибровку, если включены.\n",
    "\n",
    "    Управление временем тюнинга:\n",
    "      - tune_val_subsample: подвыборка валидации (int — кол-во, float — доля 0..1).\n",
    "      - tune_max_combinations: ограничивает число проверяемых комбо (случайно из сетки).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_ckpt: str = \"yolov8n.pt\",\n",
    "                 data_root: str | None = None,\n",
    "                 image_col: str = \"image_path\",\n",
    "                 boxes_col: str = \"boxes\",\n",
    "                 class_names: list[str] | None = None,\n",
    "                 use_symlinks: bool = True,\n",
    "                 verbose: bool = True,\n",
    "                 # переключатели\n",
    "                 enable_tuning: bool = True,\n",
    "                 enable_ridge: bool = True,\n",
    "                 validate_count: bool = True,\n",
    "                 # режим тюнинга plain vs area-gated\n",
    "                 enable_area_gate: bool = True,        # True → тюним (conf_small, conf_big, area_thr) + (iou, max_det)\n",
    "                 enable_tta_flip: bool = False,        # True → TTA flip при plain-подсчёте\n",
    "                 # управление временем тюнинга\n",
    "                 tune_val_subsample: int | float | None = None,  # int=кол-во; float=доля [0..1]\n",
    "                 tune_max_combinations: int | None = 100,\n",
    "                 random_state: int = 42,\n",
    "                 # сетки для plain-тюнинга\n",
    "                 tune_conf_grid = (0.20, 0.25, 0.30, 0.35),\n",
    "                 tune_iou_grid  = (0.55, 0.60),\n",
    "                 tune_max_det_grid = (300, 600),\n",
    "                 # сетки для area-gated (под мелкие объекты из ваших стат)\n",
    "                 tune_conf_small_grid = (0.10, 0.12, 0.14, 0.18),\n",
    "                 tune_conf_big_grid   = (0.30, 0.40, 0.50),\n",
    "                 tune_area_thr_grid   = (0.0008, 0.0010, 0.0012, 0.0015),\n",
    "                 gate_conf_base: float = 0.07,  # базовый conf для извлечения кандидатов при area-gated\n",
    "                 # сетка для Ridge\n",
    "                 ridge_alpha_grid = (0.3, 1.0, 3.0),\n",
    "                 # пороги нормированной площади для фич Ridge/plain\n",
    "                 small_thr: float = 0.0010,\n",
    "                 big_thr: float   = 0.003):\n",
    "        self.model_ckpt = model_ckpt\n",
    "        self.image_col = image_col\n",
    "        self.boxes_col = boxes_col\n",
    "        self.class_names = class_names or [\"obj\"]\n",
    "        self.use_symlinks = use_symlinks\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.enable_tuning = enable_tuning\n",
    "        self.enable_ridge = enable_ridge\n",
    "        self.validate_count = validate_count\n",
    "        self.enable_area_gate = enable_area_gate\n",
    "        self.enable_tta_flip = enable_tta_flip\n",
    "\n",
    "        self.tune_val_subsample = tune_val_subsample\n",
    "        self.tune_max_combinations = tune_max_combinations\n",
    "        self.random_state = random_state\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        # рабочая папка\n",
    "        self._tmpdir_owned = False\n",
    "        if data_root is None:\n",
    "            self.data_root = tempfile.mkdtemp(prefix=\"yolo_ds_\")\n",
    "            self._tmpdir_owned = True\n",
    "        else:\n",
    "            self.data_root = os.path.abspath(data_root)\n",
    "            os.makedirs(self.data_root, exist_ok=True)\n",
    "\n",
    "        self.dataset_yaml = os.path.join(self.data_root, \"dataset.yaml\")\n",
    "        self.model_path = None\n",
    "        self._model = None\n",
    "        self._device = None  # строка устройства, использованная при fit()\n",
    "\n",
    "        # сетки и пороги\n",
    "        self.tune_conf_grid = tuple(float(x) for x in tune_conf_grid)\n",
    "        self.tune_iou_grid  = tuple(float(x) for x in tune_iou_grid)\n",
    "        self.tune_max_det_grid = tuple(int(x) for x in tune_max_det_grid)\n",
    "\n",
    "        self.tune_conf_small_grid = tuple(float(x) for x in tune_conf_small_grid)\n",
    "        self.tune_conf_big_grid   = tuple(float(x) for x in tune_conf_big_grid)\n",
    "        self.tune_area_thr_grid   = tuple(float(x) for x in tune_area_thr_grid)\n",
    "        self.gate_conf_base = float(gate_conf_base)\n",
    "\n",
    "        self.ridge_alpha_grid = tuple(float(x) for x in ridge_alpha_grid)\n",
    "        self.small_thr = float(small_thr)\n",
    "        self.big_thr   = float(big_thr)\n",
    "\n",
    "        # сохранённые результаты тюнинга/калибровки\n",
    "        self.calib_ = dict(\n",
    "            # plain режим:\n",
    "            best_conf=None, best_iou=None, best_max_det=None,\n",
    "            # area-gated:\n",
    "            gate_conf_small=None, gate_conf_big=None, gate_area_thr=None, gate_conf_base=None,\n",
    "            # Ridge:\n",
    "            ridge_alpha=None, ridge_model=None, ridge_mu=None, ridge_sd=None,\n",
    "            # общий:\n",
    "            imgsz=None\n",
    "        )\n",
    "\n",
    "    # -------------------- device helpers --------------------\n",
    "    @staticmethod\n",
    "    def _resolve_device(device: str | int | None) -> str:\n",
    "        \"\"\"\n",
    "        Выбор устройства для обучения:\n",
    "          - None / \"auto\": \"0,1,...,N-1\" при наличии CUDA, иначе \"cpu\"\n",
    "          - иначе вернуть строку как есть (например, \"0\" или \"cpu\")\n",
    "        \"\"\"\n",
    "        if device is None or str(device).lower() == \"auto\":\n",
    "            if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "                n = torch.cuda.device_count()\n",
    "                return \",\".join(str(i) for i in range(n))\n",
    "            return \"cpu\"\n",
    "        return str(device)\n",
    "\n",
    "    def _infer_device(self) -> str:\n",
    "        \"\"\"\n",
    "        Устройство для инференса/тюнинга:\n",
    "          - если тренировались на '0,1,...' → берём первую карту '0'\n",
    "          - если тренировались на 'k' → её же\n",
    "          - иначе авто: '0' при наличии CUDA, 'cpu' без GPU\n",
    "        \"\"\"\n",
    "        if getattr(self, \"_device\", None):\n",
    "            if isinstance(self._device, str) and \",\" in self._device:\n",
    "                return self._device.split(\",\")[0]\n",
    "            return self._device\n",
    "        return \"0\" if (torch.cuda.is_available() and torch.cuda.device_count() > 0) else \"cpu\"\n",
    "\n",
    "    # -------------------- helpers: разметка → YOLO-тxt --------------------\n",
    "    @staticmethod\n",
    "    def _is_nan_like(x):\n",
    "        if x is None: return True\n",
    "        if isinstance(x, float) and np.isnan(x): return True\n",
    "        if isinstance(x, str) and x.strip()==\"\": return True\n",
    "        return False\n",
    "\n",
    "    def _parse_boxes(self, row):\n",
    "        boxes_raw = row[self.boxes_col] if self.boxes_col in row else None\n",
    "        if self._is_nan_like(boxes_raw): return []\n",
    "        out = []\n",
    "        if isinstance(boxes_raw, (list, tuple, np.ndarray)):\n",
    "            for it in boxes_raw:\n",
    "                vals = list(map(float, it))\n",
    "                if len(vals) >= 4:\n",
    "                    x,y,w,h = vals[:4]\n",
    "                    if 0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1:\n",
    "                        out.append((0, x,y,w,h))\n",
    "        elif isinstance(boxes_raw, str):\n",
    "            lines = [ln.strip() for ln in boxes_raw.strip().splitlines() if ln.strip()]\n",
    "            for ln in lines:\n",
    "                parts = ln.split()\n",
    "                vals = list(map(float, parts))\n",
    "                if len(vals) == 4:\n",
    "                    x,y,w,h = vals\n",
    "                    out.append((0, x,y,w,h))\n",
    "                elif len(vals) >= 5:\n",
    "                    cls,x,y,w,h = int(vals[0]), *vals[1:5]\n",
    "                    out.append((cls, float(x),float(y),float(w),float(h)))\n",
    "        return out\n",
    "\n",
    "    def _link_or_copy(self, src, dst):\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        if self.use_symlinks:\n",
    "            try:\n",
    "                if os.path.lexists(dst): os.remove(dst)\n",
    "                os.symlink(os.path.abspath(src), dst)\n",
    "                return\n",
    "            except Exception:\n",
    "                pass\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "    def _write_label_file(self, label_path, boxes):\n",
    "        os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
    "        with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for cls, x,y,w,h in boxes:\n",
    "                f.write(f\"{int(cls)} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "\n",
    "    def _materialize(self, train_df, val_df, train_split=\"train\", val_split=\"val\"):\n",
    "        for split_name, df in [(train_split, train_df), (val_split, val_df)]:\n",
    "            img_dir = os.path.join(self.data_root, \"images\", split_name)\n",
    "            lbl_dir = os.path.join(self.data_root, \"labels\", split_name)\n",
    "            os.makedirs(img_dir, exist_ok=True); os.makedirs(lbl_dir, exist_ok=True)\n",
    "            it = df.iterrows()\n",
    "            if self.verbose: it = tqdm(it, total=len(df), desc=f\"[build] {split_name}\")\n",
    "            for _, row in it:\n",
    "                src = row[self.image_col]\n",
    "                if not os.path.exists(src):\n",
    "                    raise FileNotFoundError(f\"Image not found: {src}\")\n",
    "                fname = os.path.basename(src)\n",
    "                stem, _ = os.path.splitext(fname)\n",
    "                self._link_or_copy(src, os.path.join(img_dir, fname))\n",
    "                self._write_label_file(os.path.join(lbl_dir, stem + \".txt\"), self._parse_boxes(row))\n",
    "\n",
    "        with open(self.dataset_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"path: {self.data_root}\\ntrain: images/{train_split}\\nval: images/{val_split}\\nnames:\\n\")\n",
    "            for i, name in enumerate(self.class_names):\n",
    "                f.write(f\"  {i}: {name}\\n\")\n",
    "\n",
    "    # -------------------- fit: train + (tune/ridge/validate) --------------------\n",
    "    def fit(self,\n",
    "            train_df: pd.DataFrame,\n",
    "            val_df: pd.DataFrame | None = None,\n",
    "            test_size: float = 0.2,\n",
    "            epochs: int = 50,\n",
    "            imgsz: int = 640,\n",
    "            batch: int = 16,\n",
    "            device: str | int | None = \"auto\",\n",
    "            workers: int = 4,\n",
    "            patience: int = 50,\n",
    "            optimizer: str = \"auto\",\n",
    "            augment: bool = True,\n",
    "            seed: int = 42,\n",
    "            close_mosaic: int | None = 10,\n",
    "            cos_lr: bool = True,\n",
    "            rect: bool = False,\n",
    "            iou: float = 0.7,\n",
    "            **extra_train_kwargs):\n",
    "\n",
    "        # выбрать устройство для тренировки и сохранить\n",
    "        self._device = self._resolve_device(device)\n",
    "        if self.verbose:\n",
    "            print(f\"[device] training device='{self._device}'\")\n",
    "\n",
    "        np.random.seed(seed); random.seed(seed)\n",
    "\n",
    "        # если val_df не задан — делаем простую стратификацию по бинам count\n",
    "        if val_df is None:\n",
    "            tmp = train_df.copy()\n",
    "            counts = [len(self._parse_boxes(r)) for _, r in tmp.iterrows()]\n",
    "            tmp[\"_bins\"] = np.clip((np.array(counts)//5).astype(int), 0, 50)\n",
    "            val_mask = tmp.groupby(\"_bins\", group_keys=False).apply(\n",
    "                lambda g: g.sample(frac=test_size, random_state=seed)).index\n",
    "            val_df = train_df.loc[val_mask]\n",
    "            train_df = train_df.drop(index=val_mask)\n",
    "            train_df = train_df.reset_index(drop=True); val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "        self._materialize(train_df, val_df)\n",
    "\n",
    "        # загрузить/скачать чекпоинт\n",
    "        if not os.path.exists(self.model_ckpt) and self.model_ckpt.endswith(\".pt\"):\n",
    "            try:\n",
    "                if self.verbose: print(f\"Checkpoint '{self.model_ckpt}' not found. Attempting to download...\")\n",
    "                attempt_download_asset(self.model_ckpt)\n",
    "            except Exception as e:\n",
    "                raise FileNotFoundError(f\"Failed to download '{self.model_ckpt}'. Error: {e}\")\n",
    "\n",
    "        # train args\n",
    "        train_args = {\n",
    "            'data': self.dataset_yaml, 'epochs': epochs, 'imgsz': imgsz, 'batch': batch,\n",
    "            'device': self._device, 'workers': workers, 'patience': patience, 'optimizer': optimizer,\n",
    "            'augment': augment, 'seed': seed, 'close_mosaic': close_mosaic, 'cos_lr': cos_lr,\n",
    "            'rect': rect, 'iou': iou, 'verbose': self.verbose\n",
    "        }\n",
    "        train_args.update(extra_train_kwargs)\n",
    "\n",
    "        # обучение\n",
    "        model = YOLO(self.model_ckpt)\n",
    "        model.train(**train_args)\n",
    "\n",
    "        # ГАРАНТИРОВАННО берём лучший чекпоинт\n",
    "        best_path = None\n",
    "        if hasattr(model, \"trainer\") and getattr(model.trainer, \"best\", None):\n",
    "            best_path = str(model.trainer.best)     # .../runs/detect/exp/weights/best.pt\n",
    "        elif getattr(model, \"ckpt_path\", None):\n",
    "            best_path = str(model.ckpt_path)\n",
    "        else:\n",
    "            best_path = self.model_ckpt\n",
    "        self.model_path = best_path\n",
    "        if self.verbose:\n",
    "            print(f\"[fit] best model: {self.model_path}\")\n",
    "\n",
    "        # тюнинг/калибровка/валидация\n",
    "        try:\n",
    "            self._tune_and_or_calibrate(val_df, imgsz=imgsz)\n",
    "            if self.validate_count:\n",
    "                self._validate_counting(val_df)\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"[post-fit] skipped tuning/calibration/validation due to: {e}\")\n",
    "\n",
    "        return self.model_path\n",
    "\n",
    "    # -------------------- инференс-хелперы --------------------\n",
    "    def _ensure_model(self):\n",
    "        if self._model is None:\n",
    "            path = self.model_path or self.model_ckpt\n",
    "            self._model = YOLO(path)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _raw_counts(self, paths, imgsz, conf, iou, max_det):\n",
    "        \"\"\"Plain len(detections). Если enable_tta_flip=True — усреднение с augment=True.\"\"\"\n",
    "        self._ensure_model()\n",
    "        out = []\n",
    "        dev = self._infer_device()\n",
    "        if not self.enable_tta_flip:\n",
    "            for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[counts]\"):\n",
    "                batch = paths[i:i+64]\n",
    "                res = self._model.predict(batch, imgsz=imgsz, conf=conf, iou=iou,\n",
    "                                          max_det=max_det, device=dev, verbose=False)\n",
    "                for r in res:\n",
    "                    out.append(int(len(r.boxes) if (r.boxes is not None) else 0))\n",
    "        else:\n",
    "            for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[counts-tta]\"):\n",
    "                batch = paths[i:i+64]\n",
    "                r1 = self._model.predict(batch, imgsz=imgsz, conf=conf, iou=iou,\n",
    "                                         max_det=max_det, device=dev, verbose=False)\n",
    "                r2 = self._model.predict(batch, imgsz=imgsz, conf=conf, iou=iou,\n",
    "                                         max_det=max_det, device=dev, verbose=False, augment=True)\n",
    "                for a, b in zip(r1, r2):\n",
    "                    n1 = int(len(a.boxes) if (a.boxes is not None) else 0)\n",
    "                    n2 = int(len(b.boxes) if (b.boxes is not None) else 0)\n",
    "                    out.append(0.5 * (n1 + n2))\n",
    "        return np.array(out, dtype=float)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _yolo_feats(self, paths, imgsz, conf, iou, max_det):\n",
    "        \"\"\"Фичи для Ridge: [n, conf_sum, conf_mean, conf_max, area_mean, frac_small, frac_mid, frac_big].\"\"\"\n",
    "        self._ensure_model()\n",
    "        rows = []\n",
    "        dev = self._infer_device()\n",
    "        for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[feats]\"):\n",
    "            batch = paths[i:i+64]\n",
    "            res = self._model.predict(batch, imgsz=imgsz, conf=conf, iou=iou,\n",
    "                                      max_det=max_det, device=dev, verbose=False)\n",
    "            for r in res:\n",
    "                if r.boxes is None or len(r.boxes) == 0:\n",
    "                    rows.append(dict(n=0, conf_sum=0, conf_mean=0, conf_max=0,\n",
    "                                     area_mean=0, frac_small=0, frac_mid=0, frac_big=0))\n",
    "                    continue\n",
    "                confs = r.boxes.conf.cpu().numpy()\n",
    "                xywhn = r.boxes.xywhn.cpu().numpy()\n",
    "                areas = (xywhn[:, 2] * xywhn[:, 3]).clip(0, 1)\n",
    "                rows.append(dict(\n",
    "                    n=len(confs),\n",
    "                    conf_sum=float(confs.sum()),\n",
    "                    conf_mean=float(confs.mean()),\n",
    "                    conf_max=float(confs.max()),\n",
    "                    area_mean=float(areas.mean()),\n",
    "                    frac_small=float((areas < self.small_thr).mean()),\n",
    "                    frac_mid=float(((areas >= self.small_thr) & (areas <= self.big_thr)).mean()),\n",
    "                    frac_big=float((areas > self.big_thr).mean())\n",
    "                ))\n",
    "        return pd.DataFrame(rows).to_numpy()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _detect_conf_area(self, paths, imgsz, conf_base, iou, max_det):\n",
    "        \"\"\"Возвращает список массивов Nx2 [conf, area] при базовом пороге conf_base (для area-gated).\"\"\"\n",
    "        self._ensure_model()\n",
    "        dev = self._infer_device()\n",
    "        out = []\n",
    "        for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[boxes]\"):\n",
    "            batch = paths[i:i+64]\n",
    "            res = self._model.predict(batch, imgsz=imgsz, conf=conf_base, iou=iou,\n",
    "                                      max_det=max_det, device=dev, verbose=False)\n",
    "            for r in res:\n",
    "                if r.boxes is None or len(r.boxes) == 0:\n",
    "                    out.append(np.empty((0, 2), dtype=np.float32))\n",
    "                    continue\n",
    "                confs = r.boxes.conf.cpu().numpy()\n",
    "                xywhn = r.boxes.xywhn.cpu().numpy()\n",
    "                areas = (xywhn[:, 2] * xywhn[:, 3]).clip(0, 1)\n",
    "                out.append(np.stack([confs, areas], axis=1))\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_with_area_gate(conf_area_list, conf_small, conf_big, area_thr):\n",
    "        \"\"\"Подсчёт с двупороговой фильтрацией по площади.\"\"\"\n",
    "        counts = []\n",
    "        for ca in conf_area_list:\n",
    "            if ca.size == 0:\n",
    "                counts.append(0); continue\n",
    "            conf = ca[:, 0]; area = ca[:, 1]\n",
    "            small_mask = (area < area_thr)  & (conf >= conf_small)\n",
    "            big_mask   = (area >= area_thr) & (conf >= conf_big)\n",
    "            counts.append(int(small_mask.sum() + big_mask.sum()))\n",
    "        return np.array(counts, dtype=float)\n",
    "\n",
    "    # -------------------- подвыборка валидации --------------------\n",
    "    def _subset_val(self, val_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.tune_val_subsample is None:\n",
    "            return val_df\n",
    "        n = len(val_df)\n",
    "        if isinstance(self.tune_val_subsample, float):\n",
    "            k = max(1, int(round(n * self.tune_val_subsample)))\n",
    "        else:\n",
    "            k = int(self.tune_val_subsample)\n",
    "        k = min(k, n)\n",
    "        return val_df.sample(n=k, random_state=self.random_state).reset_index(drop=True)\n",
    "\n",
    "    # -------------------- Ridge по резидуалу с K-fold CV --------------------\n",
    "    def _fit_ridge_cv_on_residual(self, X: np.ndarray, y_true: np.ndarray, y_plain: np.ndarray):\n",
    "        alphas = self.ridge_alpha_grid\n",
    "        k = min(5, len(y_true)) if len(y_true) >= 3 else 2\n",
    "        kf = KFold(n_splits=k, shuffle=True, random_state=self.random_state)\n",
    "\n",
    "        # стандартизация фич\n",
    "        mu = X.mean(axis=0)\n",
    "        sd = X.std(axis=0); sd[sd == 0] = 1.0\n",
    "        Xs = (X - mu) / sd\n",
    "        r = y_true - y_plain\n",
    "\n",
    "        best_alpha, best_cv = None, 1e9\n",
    "        for a in alphas:\n",
    "            cv_scores = []\n",
    "            for tr, va in kf.split(Xs):\n",
    "                m = Ridge(alpha=float(a)).fit(Xs[tr], r[tr])\n",
    "                pr = m.predict(Xs[va])\n",
    "                cv_scores.append(mean_squared_error(r[va], pr, squared=False))\n",
    "            cv_rmse = float(np.mean(cv_scores))\n",
    "            if cv_rmse < best_cv:\n",
    "                best_alpha, best_cv = float(a), cv_rmse\n",
    "\n",
    "        # финальная подгонка на всех\n",
    "        model = Ridge(alpha=best_alpha).fit(Xs, r)\n",
    "        return dict(model=model, alpha=best_alpha, mu=mu, sd=sd, cv_rmse=best_cv)\n",
    "\n",
    "    # -------------------- тюнинг и/или калибровка --------------------\n",
    "    def _tune_and_or_calibrate(self, val_df: pd.DataFrame, imgsz: int):\n",
    "        val_sub = self._subset_val(val_df)\n",
    "        paths = val_sub[self.image_col].tolist()\n",
    "        y_true = np.array([len(self._parse_boxes(r)) for _, r in val_sub.iterrows()], dtype=float)\n",
    "\n",
    "        # 1) Тюнинг plain или area-gated\n",
    "        if self.enable_tuning:\n",
    "            if self.enable_area_gate:\n",
    "                # Подготовим базовый порог для сбора кандидатов, согласованный с минимальным cs\n",
    "                min_cs = min(self.tune_conf_small_grid) if len(self.tune_conf_small_grid) else 0.10\n",
    "                base_collect = max(0.03, min(self.gate_conf_base, min_cs - 0.02))\n",
    "                if self.verbose:\n",
    "                    print(f\"[tune-gate] base_collect={base_collect:.3f} (min_cs={min_cs:.3f})\")\n",
    "\n",
    "                # 1) Предрасчёт списков [conf, area] для всех (iou, max_det)\n",
    "                iou_grid = tuple(self.tune_iou_grid)\n",
    "                md_grid  = tuple(self.tune_max_det_grid)\n",
    "                conf_area_by_key = {}\n",
    "                total_prepasses = len(iou_grid) * len(md_grid)\n",
    "                if self.verbose:\n",
    "                    print(f\"[tune-gate] precomputing boxes for {total_prepasses} (iou,max_det) pairs...\")\n",
    "                for iou_ in iou_grid:\n",
    "                    for md_ in md_grid:\n",
    "                        conf_area_by_key[(iou_, md_)] = self._detect_conf_area(\n",
    "                            paths, imgsz=imgsz,\n",
    "                            conf_base=float(base_collect),\n",
    "                            iou=float(iou_), max_det=int(md_)\n",
    "                        )\n",
    "\n",
    "                # 2) Подбор cs/cb/area_thr + iou/max_det\n",
    "                all_combos = []\n",
    "                for iou_ in iou_grid:\n",
    "                    for md_ in md_grid:\n",
    "                        for cs in self.tune_conf_small_grid:\n",
    "                            # эффективная база (ниже cs)\n",
    "                            base_eff = max(0.03, min(float(self.gate_conf_base), float(cs) - 0.02))\n",
    "                            for cb in self.tune_conf_big_grid:\n",
    "                                for at in self.tune_area_thr_grid:\n",
    "                                    all_combos.append((float(iou_), int(md_), float(cs), float(cb), float(at), float(base_eff)))\n",
    "\n",
    "                random.shuffle(all_combos)\n",
    "                full_space = len(all_combos)\n",
    "                if self.tune_max_combinations is not None:\n",
    "                    all_combos = all_combos[:int(self.tune_max_combinations)]\n",
    "                if self.verbose:\n",
    "                    print(f\"[tune-gate] search combos: {len(all_combos)} (cap), full={full_space}\")\n",
    "\n",
    "                best = dict(rmse=1e9, iou=None, max_det=None, cs=None, cb=None, at=None, base=None)\n",
    "                for (iou_, md_, cs, cb, at, base_eff) in all_combos:\n",
    "                    conf_area = conf_area_by_key[(iou_, md_)]\n",
    "                    y_pred = self._count_with_area_gate(conf_area, cs, cb, at)\n",
    "                    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "                    if rmse < best[\"rmse\"]:\n",
    "                        best.update(dict(rmse=rmse, iou=iou_, max_det=md_,\n",
    "                                         cs=cs, cb=cb, at=at, base=base_eff))\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f\"[tune-gate] best: cs={best['cs']:.3f}, cb={best['cb']:.3f}, \"\n",
    "                          f\"area_thr={best['at']:.4f}, iou={best['iou']}, max_det={best['max_det']}  RMSE={best['rmse']:.3f}\")\n",
    "\n",
    "                self.calib_.update(dict(\n",
    "                    best_conf=None, best_iou=float(best['iou']), best_max_det=int(best['max_det']),\n",
    "                    gate_conf_small=float(best['cs']), gate_conf_big=float(best['cb']),\n",
    "                    gate_area_thr=float(best['at']), gate_conf_base=float(best['base'])\n",
    "                ))\n",
    "            else:\n",
    "                combos = [(float(c), float(i), int(m))\n",
    "                          for i in self.tune_iou_grid\n",
    "                          for m in self.tune_max_det_grid\n",
    "                          for c in self.tune_conf_grid]\n",
    "                random.shuffle(combos)\n",
    "                full_space = len(combos)\n",
    "                if self.tune_max_combinations is not None:\n",
    "                    combos = combos[:int(self.tune_max_combinations)]\n",
    "                if self.verbose:\n",
    "                    print(f\"[tune-plain] search combos: {len(combos)} (cap), full={full_space}\")\n",
    "\n",
    "                best = dict(rmse=1e9, conf=None, iou=None, max_det=None)\n",
    "                for conf, iou_v, max_det in combos:\n",
    "                    y_pred = self._raw_counts(paths, imgsz=imgsz, conf=conf, iou=iou_v, max_det=max_det)\n",
    "                    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "                    if rmse < best[\"rmse\"]:\n",
    "                        best.update(dict(rmse=rmse, conf=conf, iou=iou_v, max_det=max_det))\n",
    "                if self.verbose:\n",
    "                    print(f\"[tune] best plain count: conf={best['conf']}, iou={best['iou']}, max_det={best['max_det']}  RMSE={best['rmse']:.3f}\")\n",
    "\n",
    "                self.calib_.update(dict(\n",
    "                    best_conf=best['conf'], best_iou=best['iou'], best_max_det=best['max_det'],\n",
    "                    gate_conf_small=None, gate_conf_big=None, gate_area_thr=None, gate_conf_base=None\n",
    "                ))\n",
    "        else:\n",
    "            # без тюнинга — дефолты для plain\n",
    "            self.calib_.update(dict(\n",
    "                best_conf=0.25, best_iou=0.5, best_max_det=1000,\n",
    "                gate_conf_small=None, gate_conf_big=None, gate_area_thr=None, gate_conf_base=None\n",
    "            ))\n",
    "\n",
    "        # 2) Калибровка Ridge (по резидуалу, с CV)\n",
    "        ridge_model, ridge_alpha = None, None\n",
    "        if self.enable_ridge:\n",
    "            # строим y_plain на том же сабсете val_sub\n",
    "            if self.enable_tuning and self.enable_area_gate and self.calib_.get(\"gate_conf_small\") is not None:\n",
    "                iou_use = float(self.calib_[\"best_iou\"])\n",
    "                md_use  = int(self.calib_[\"best_max_det\"])\n",
    "                conf_area = self._detect_conf_area(paths, imgsz=imgsz,\n",
    "                                                   conf_base=float(self.calib_[\"gate_conf_base\"]),\n",
    "                                                   iou=iou_use, max_det=md_use)\n",
    "                y_plain = self._count_with_area_gate(conf_area,\n",
    "                                                     float(self.calib_[\"gate_conf_small\"]),\n",
    "                                                     float(self.calib_[\"gate_conf_big\"]),\n",
    "                                                     float(self.calib_[\"gate_area_thr\"]))\n",
    "                X = self._yolo_feats(paths, imgsz=imgsz,\n",
    "                                     conf=float(self.calib_[\"gate_conf_base\"]),\n",
    "                                     iou=iou_use, max_det=md_use)\n",
    "            else:\n",
    "                conf_use = float(self.calib_[\"best_conf\"] if self.calib_.get(\"best_conf\") is not None else 0.25)\n",
    "                iou_use  = float(self.calib_[\"best_iou\"]  if self.calib_.get(\"best_iou\")  is not None else 0.5)\n",
    "                md_use   = int(self.calib_[\"best_max_det\"] if self.calib_.get(\"best_max_det\") is not None else 1000)\n",
    "                y_plain  = self._raw_counts(paths, imgsz=imgsz, conf=conf_use, iou=iou_use, max_det=md_use)\n",
    "                X = self._yolo_feats(paths, imgsz=imgsz, conf=conf_use, iou=iou_use, max_det=md_use)\n",
    "\n",
    "            pack = self._fit_ridge_cv_on_residual(X, y_true, y_plain)\n",
    "            ridge_model, ridge_alpha = pack[\"model\"], pack[\"alpha\"]\n",
    "            if self.verbose:\n",
    "                print(f\"[calib] Ridge(residual) alpha={ridge_alpha}  CV-RMSE(resid)={pack['cv_rmse']:.3f}\")\n",
    "\n",
    "            # сохраним стандартизацию\n",
    "            self.calib_.update(dict(\n",
    "                ridge_alpha=ridge_alpha, ridge_model=ridge_model,\n",
    "                ridge_mu=pack[\"mu\"], ridge_sd=pack[\"sd\"], imgsz=imgsz\n",
    "            ))\n",
    "        else:\n",
    "            self.calib_.update(dict(ridge_alpha=None, ridge_model=None, imgsz=imgsz))\n",
    "\n",
    "    # -------------------- финальная валидация подсчёта --------------------\n",
    "    def _validate_counting(self, val_df: pd.DataFrame):\n",
    "        paths = val_df[self.image_col].tolist()\n",
    "        y_true = np.array([len(self._parse_boxes(r)) for _, r in val_df.iterrows()], dtype=float)\n",
    "\n",
    "        imgsz = self.calib_['imgsz'] or 640\n",
    "\n",
    "        # plain/gate\n",
    "        if self.enable_tuning and self.enable_area_gate and self.calib_.get(\"gate_conf_small\") is not None:\n",
    "            iou_use = float(self.calib_[\"best_iou\"])\n",
    "            md_use  = int(self.calib_[\"best_max_det\"])\n",
    "            conf_area = self._detect_conf_area(paths, imgsz=imgsz, conf_base=self.calib_[\"gate_conf_base\"],\n",
    "                                               iou=iou_use, max_det=md_use)\n",
    "            y_plain = self._count_with_area_gate(conf_area,\n",
    "                                                 self.calib_[\"gate_conf_small\"],\n",
    "                                                 self.calib_[\"gate_conf_big\"],\n",
    "                                                 self.calib_[\"gate_area_thr\"])\n",
    "        else:\n",
    "            conf  = self.calib_['best_conf'] if self.enable_tuning else 0.25\n",
    "            iou_v   = self.calib_['best_iou']  if self.enable_tuning else 0.5\n",
    "            max_det = self.calib_['best_max_det'] if self.enable_tuning else 1000\n",
    "            y_plain = self._raw_counts(paths, imgsz, conf, iou_v, max_det)\n",
    "\n",
    "        rmse_plain = mean_squared_error(y_true, y_plain, squared=False)\n",
    "        mae_plain  = mean_absolute_error(y_true, y_plain)\n",
    "\n",
    "        # calibrated\n",
    "        if self.enable_ridge and self.calib_['ridge_model'] is not None:\n",
    "            if self.enable_tuning and self.enable_area_gate and self.calib_.get(\"gate_conf_small\") is not None:\n",
    "                X = self._yolo_feats(paths, imgsz=imgsz, conf=float(self.calib_[\"gate_conf_base\"]),\n",
    "                                     iou=float(self.calib_[\"best_iou\"]), max_det=int(self.calib_[\"best_max_det\"]))\n",
    "            else:\n",
    "                X = self._yolo_feats(paths, imgsz=imgsz,\n",
    "                                     conf=(self.calib_[\"best_conf\"] if self.calib_[\"best_conf\"] is not None else 0.25),\n",
    "                                     iou=(self.calib_[\"best_iou\"] if self.calib_[\"best_iou\"] is not None else 0.5),\n",
    "                                     max_det=(self.calib_[\"best_max_det\"] if self.calib_[\"best_max_det\"] is not None else 1000))\n",
    "            mu = self.calib_.get(\"ridge_mu\"); sd = self.calib_.get(\"ridge_sd\")\n",
    "            Xs = (X - mu) / sd\n",
    "            resid = self.calib_['ridge_model'].predict(Xs)\n",
    "            y_cal = np.clip(y_plain + resid, 0, None)\n",
    "            rmse_cal = mean_squared_error(y_true, y_cal, squared=False)\n",
    "            mae_cal  = mean_absolute_error(y_true, y_cal)\n",
    "            print(f\"[val-count] plain: RMSE={rmse_plain:.3f}, MAE={mae_plain:.3f}  |  calibrated: RMSE={rmse_cal:.3f}, MAE={mae_cal:.3f}\")\n",
    "        else:\n",
    "            print(f\"[val-count] plain: RMSE={rmse_plain:.3f}, MAE={mae_plain:.3f}  |  calibrated: (disabled)\")\n",
    "\n",
    "    # -------------------- публичный инференс: детекции --------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, df: pd.DataFrame,\n",
    "                conf: float = 0.25, iou: float = 0.6,\n",
    "                imgsz: int = 640, device: str | int | None = \"auto\",\n",
    "                max_det: int = 300, agnostic_nms: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"Детекции (калибровка НЕ используется).\"\"\"\n",
    "        assert self.image_col in df.columns\n",
    "        if self._model is None:\n",
    "            self._model = YOLO(self.model_path or self.model_ckpt)\n",
    "\n",
    "        dev = self._resolve_device(device if device is not None else self._infer_device())\n",
    "\n",
    "        paths = df[self.image_col].tolist()\n",
    "        preds = []\n",
    "        for i in tqdm(range(0, len(paths), 64), disable=not self.verbose, desc=\"[predict]\"):\n",
    "            batch = paths[i:i+64]\n",
    "            res = self._model(batch, conf=conf, iou=iou, imgsz=imgsz,\n",
    "                              device=dev, verbose=False, max_det=max_det,\n",
    "                              agnostic_nms=agnostic_nms)\n",
    "            for r in res:\n",
    "                boxes = []\n",
    "                if r.boxes is not None and len(r.boxes):\n",
    "                    xywhn = r.boxes.xywhn.cpu().numpy()\n",
    "                    confv = r.boxes.conf.cpu().numpy()\n",
    "                    clsv  = r.boxes.cls.cpu().numpy().astype(int)\n",
    "                    for (x,y,w,h), c, k in zip(xywhn, confv, clsv):\n",
    "                        boxes.append({\"cls\": int(k), \"conf\": float(c),\n",
    "                                      \"x\": float(x), \"y\": float(y), \"w\": float(w), \"h\": float(h)})\n",
    "                preds.append({\n",
    "                    self.image_col: r.path,\n",
    "                    \"count\": len(boxes),\n",
    "                    \"boxes_json\": json.dumps(boxes, ensure_ascii=False)\n",
    "                })\n",
    "        return pd.DataFrame(preds)\n",
    "\n",
    "    # -------------------- публичный инференс: подсчёт --------------------\n",
    "    @torch.no_grad()\n",
    "    def predict_counts(self, df: pd.DataFrame,\n",
    "                       imgsz: int | None = None,\n",
    "                       conf: float | None = None,\n",
    "                       iou: float | None = None,\n",
    "                       max_det: int | None = None,\n",
    "                       device: str | int | None = \"auto\",\n",
    "                       clamp_nonneg: bool = True,\n",
    "                       do_round: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Подсчёт объектов.\n",
    "          - Если enable_ridge=True и калибратор обучен → y = y_plain + Ridge(residual).\n",
    "          - Иначе → plain len(dets).\n",
    "          - Если enable_area_gate=True и тюнинг выполнен → двупороговая фильтрация (conf_small/conf_big) по area.\n",
    "        \"\"\"\n",
    "        assert self.image_col in df.columns\n",
    "        if self._model is None:\n",
    "            self._model = YOLO(self.model_path or self.model_ckpt)\n",
    "\n",
    "        dev = self._resolve_device(device if device is not None else self._infer_device())\n",
    "        imgsz = imgsz or self.calib_['imgsz'] or 640\n",
    "        paths = df[self.image_col].tolist()\n",
    "\n",
    "        # area-gated путь\n",
    "        if self.enable_tuning and self.enable_area_gate and self.calib_.get(\"gate_conf_small\") is not None:\n",
    "            conf_base = float(self.calib_[\"gate_conf_base\"])\n",
    "            iou_use   = float(self.calib_[\"best_iou\"])\n",
    "            max_det_use = int(self.calib_[\"best_max_det\"])\n",
    "            conf_area = self._detect_conf_area(paths, imgsz=imgsz, conf_base=conf_base, iou=iou_use, max_det=max_det_use)\n",
    "            cs, cb, at = float(self.calib_[\"gate_conf_small\"]), float(self.calib_[\"gate_conf_big\"]), float(self.calib_[\"gate_area_thr\"])\n",
    "            y_plain = self._count_with_area_gate(conf_area, cs, cb, at)\n",
    "\n",
    "            if self.enable_ridge and self.calib_.get(\"ridge_model\") is not None:\n",
    "                X = self._yolo_feats(paths, imgsz=imgsz, conf=conf_base, iou=iou_use, max_det=max_det_use)\n",
    "                # стандартизация и предсказание резидуала\n",
    "                mu = self.calib_.get(\"ridge_mu\"); sd = self.calib_.get(\"ridge_sd\")\n",
    "                Xs = (X - mu) / sd\n",
    "                resid = self.calib_['ridge_model'].predict(Xs)\n",
    "                y = y_plain + resid\n",
    "            else:\n",
    "                y = y_plain\n",
    "\n",
    "        else:\n",
    "            # обычный plain путь\n",
    "            if self.enable_tuning and self.calib_.get(\"best_conf\") is not None:\n",
    "                conf_def, iou_def, max_det_def = self.calib_['best_conf'], self.calib_['best_iou'], self.calib_['best_max_det']\n",
    "            else:\n",
    "                conf_def, iou_def, max_det_def = 0.25, 0.5, 1000\n",
    "\n",
    "            use_conf  = conf    if conf    is not None else conf_def\n",
    "            use_iou   = iou     if iou     is not None else iou_def\n",
    "            use_maxdet= max_det if max_det is not None else max_det_def\n",
    "\n",
    "            if self.enable_ridge and self.calib_.get(\"ridge_model\") is not None:\n",
    "                X = self._yolo_feats(paths, imgsz=imgsz, conf=use_conf, iou=use_iou, max_det=use_maxdet)\n",
    "                mu = self.calib_.get(\"ridge_mu\"); sd = self.calib_.get(\"ridge_sd\")\n",
    "                Xs = (X - mu) / sd\n",
    "                resid = self.calib_['ridge_model'].predict(Xs)\n",
    "                # базовый plain-счёт для сложения с резидуалом:\n",
    "                y_plain = self._raw_counts(paths, imgsz=imgsz, conf=use_conf, iou=use_iou, max_det=use_maxdet)\n",
    "                y = y_plain + resid\n",
    "            else:\n",
    "                y = self._raw_counts(paths, imgsz=imgsz, conf=use_conf, iou=use_iou, max_det=use_maxdet)\n",
    "\n",
    "        if clamp_nonneg: y = np.clip(y, 0, None)\n",
    "        if do_round:     y = np.rint(y)\n",
    "\n",
    "        out = df[[self.image_col]].copy()\n",
    "        out[\"label\"] = y\n",
    "        return out\n",
    "\n",
    "    # -------------------- housekeeping --------------------\n",
    "    def cleanup(self):\n",
    "        if self._tmpdir_owned and os.path.isdir(self.data_root):\n",
    "            shutil.rmtree(self.data_root, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f265ff06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T04:39:02.968842Z",
     "iopub.status.busy": "2025-09-16T04:39:02.968570Z",
     "iopub.status.idle": "2025-09-16T04:39:02.972024Z",
     "shell.execute_reply": "2025-09-16T04:39:02.971437Z"
    },
    "papermill": {
     "duration": 0.026099,
     "end_time": "2025-09-16T04:39:02.973181",
     "exception": false,
     "start_time": "2025-09-16T04:39:02.947082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547471ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T04:39:03.013869Z",
     "iopub.status.busy": "2025-09-16T04:39:03.013622Z",
     "iopub.status.idle": "2025-09-16T04:39:08.626038Z",
     "shell.execute_reply": "2025-09-16T04:39:08.625214Z"
    },
    "papermill": {
     "duration": 5.633984,
     "end_time": "2025-09-16T04:39:08.627509",
     "exception": false,
     "start_time": "2025-09-16T04:39:02.993525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def read_yolo_txt(txt_path: str) -> list[list[float]]:\n",
    "    boxes = []\n",
    "    if os.path.exists(txt_path):\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for ln in f:\n",
    "                p = ln.strip().split()\n",
    "                if len(p) >= 5:\n",
    "                    x, y, w, h = map(float, p[1:5])  # cls x y w h → берём координаты\n",
    "                    if 0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1:\n",
    "                        boxes.append([x, y, w, h])\n",
    "    return boxes\n",
    "\n",
    "def df_from_dirs(images_dir: str, labels_dir: str) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for img_path in sorted(glob(os.path.join(images_dir, \"*\"))):\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "        stem = Path(img_path).stem\n",
    "        txt_path = os.path.join(labels_dir, stem + \".txt\")\n",
    "        boxes = read_yolo_txt(txt_path)\n",
    "        rows.append({\"image_path\": img_path, \"label\": boxes})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# подставьте ваши реальные пути\n",
    "train_img_dir = \"/kaggle/input/all-cups-workout-seagulls/train/train/images/\"\n",
    "train_lbl_dir = \"/kaggle/input/all-cups-workout-seagulls/train/train/labels/\"\n",
    "valid_img_dir = \"/kaggle/input/all-cups-workout-seagulls/train/valid/images/\"\n",
    "valid_lbl_dir = \"/kaggle/input/all-cups-workout-seagulls/train/valid/labels/\"\n",
    "test_img = \"/kaggle/input/all-cups-workout-seagulls/test/images/\"\n",
    "\n",
    "train_df = df_from_dirs(train_img_dir, train_lbl_dir)\n",
    "val_df = df_from_dirs(valid_img_dir, valid_lbl_dir)\n",
    "\n",
    "submission_data = pd.DataFrame({\n",
    "    \"image_path\": sorted(glob(os.path.join(test_img, \"*\")))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b486e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T04:39:08.667671Z",
     "iopub.status.busy": "2025-09-16T04:39:08.667441Z",
     "iopub.status.idle": "2025-09-16T04:44:58.324663Z",
     "shell.execute_reply": "2025-09-16T04:44:58.323917Z"
    },
    "papermill": {
     "duration": 349.678479,
     "end_time": "2025-09-16T04:44:58.325940",
     "exception": false,
     "start_time": "2025-09-16T04:39:08.647461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[device] training device='0,1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[build] train: 100%|██████████| 500/500 [00:00<00:00, 1303.19it/s]\n",
      "[build] val: 100%|██████████| 99/99 [00:00<00:00, 3325.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 'yolov8n.pt' not found. Attempting to download...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 66.0MB/s 0.1s\n",
      "Ultralytics 8.3.200 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/tmp/yolo_ds_mafoppgg/dataset.yaml, degrees=0.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.5, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=True, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 17.0MB/s 0.0s\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "WARNING ⚠️ 'rect=True' is incompatible with Multi-GPU training, setting 'rect=False'\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 40901 /root/.config/Ultralytics/DDP/_temp_h6mijri_138855249288976.py\n",
      "Ultralytics 8.3.200 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 72.6MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 7.1±2.8 MB/s, size: 54.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /tmp/yolo_ds_mafoppgg/labels/train... 500 images, 32 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 500/500 416.2it/s 1.2s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/yolo_ds_mafoppgg/images/train/20200816_180222_01_JPG.rf.5f3bc87ff01f17b2a00c3ecf18d14ac5.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/yolo_ds_mafoppgg/images/train/20200819_182328_01_JPG.rf.cca24be539aa73a24a2bf112ab67fe68.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/yolo_ds_mafoppgg/images/train/20200910_185837_01_JPG.rf.cdf85cd8e98797d94fb93d972d58fc5f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/yolo_ds_mafoppgg/images/train/20200913_121758_01_JPG.rf.126b4bd798cd834f2c08f1c85a6fee70.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/yolo_ds_mafoppgg/images/train/20200913_171925_01_JPG.rf.de1d151832416a3f2df30dcdbf84bf8a.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/tmp/yolo_ds_mafoppgg/images/train/20200924_183741_01_JPG.rf.cbc768e717616cc48643dba4f3a76bbd.jpg: 3 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /tmp/yolo_ds_mafoppgg/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 8.5±3.3 MB/s, size: 51.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /tmp/yolo_ds_mafoppgg/labels/val... 99 images, 65 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 99/99 428.6it/s 0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /tmp/yolo_ds_mafoppgg/labels/val.cache\n",
      "Plotting labels to /kaggle/working/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/runs/detect/train\u001b[0m\n",
      "Starting training for 60 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/60      2.22G      2.557      3.334      1.203         70        640: 100% ━━━━━━━━━━━━ 16/16 2.6it/s 6.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
      "                   all         99        110    0.00368      0.836     0.0116    0.00399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/60       2.4G      2.233       1.65      1.141        151        640: 100% ━━━━━━━━━━━━ 16/16 4.0it/s 4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.9it/s 0.6s\n",
      "                   all         99        110    0.00405      0.836     0.0101    0.00368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/60      2.42G       2.16      1.483      1.092        112        640: 100% ━━━━━━━━━━━━ 16/16 3.9it/s 4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.8it/s 0.6s\n",
      "                   all         99        110    0.00352      0.827     0.0125    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/60      2.44G      2.124      1.375      1.088        144        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.2it/s 0.6s\n",
      "                   all         99        110    0.00304        0.8      0.507       0.23\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/60      2.46G      2.069      1.318      1.068        164        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.4it/s 0.7s\n",
      "                   all         99        110      0.874      0.317       0.53      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/60      2.48G      2.061      1.307      1.096        190        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.8it/s 0.7s\n",
      "                   all         99        110      0.831      0.527       0.64      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/60      2.49G      2.052      1.233       1.06        150        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.9it/s 0.6s\n",
      "                   all         99        110      0.536      0.627      0.459      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/60      2.51G      2.044      1.221      1.081        126        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.0it/s 0.8s\n",
      "                   all         99        110      0.385      0.695      0.347      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/60      2.53G      2.056      1.236      1.079        222        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.8it/s 0.7s\n",
      "                   all         99        110      0.839      0.682       0.74      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/60      2.55G       1.98       1.13      1.058        162        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.6it/s 0.6s\n",
      "                   all         99        110      0.871      0.664      0.775      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/60      2.56G      2.019      1.148      1.057        199        640: 100% ━━━━━━━━━━━━ 16/16 4.0it/s 4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.8it/s 0.6s\n",
      "                   all         99        110      0.758      0.745      0.764      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/60      2.58G      1.988      1.132      1.058        132        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.4it/s 0.5s\n",
      "                   all         99        110      0.833      0.728      0.769      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/60       2.6G      2.023      1.114      1.061        164        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.5it/s 0.6s\n",
      "                   all         99        110       0.86      0.785      0.813      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/60      2.62G      1.921       1.06      1.053         87        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.7it/s 0.7s\n",
      "                   all         99        110      0.902      0.671      0.781      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/60      2.63G      2.001      1.108      1.063        171        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.5it/s 0.6s\n",
      "                   all         99        110      0.844      0.682      0.769      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/60      2.65G      1.936      1.066      1.067        164        640: 100% ━━━━━━━━━━━━ 16/16 4.4it/s 3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.7it/s 0.7s\n",
      "                   all         99        110      0.819      0.755      0.823      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/60      2.67G      1.939      1.076      1.071        154        640: 100% ━━━━━━━━━━━━ 16/16 4.0it/s 4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.9it/s 0.6s\n",
      "                   all         99        110      0.886      0.736      0.842      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/60      2.68G      1.903      1.042      1.047        122        640: 100% ━━━━━━━━━━━━ 16/16 4.4it/s 3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.3it/s 0.7s\n",
      "                   all         99        110      0.776      0.691      0.743      0.333\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/60       2.7G      1.937      1.065      1.058        140        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.6it/s 0.7s\n",
      "                   all         99        110      0.836      0.745       0.83      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/60      2.72G      1.924      1.041      1.049        150        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.4it/s 0.6s\n",
      "                   all         99        110      0.862      0.736      0.837      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/60      2.73G      1.924      1.034      1.046        142        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.9it/s 0.7s\n",
      "                   all         99        110      0.799      0.725       0.78      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/60      2.75G      1.906      1.044      1.066        129        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.8it/s 0.7s\n",
      "                   all         99        110      0.878      0.755       0.83      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/60      2.77G       1.94      1.007      1.032        232        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.6it/s 0.6s\n",
      "                   all         99        110      0.853      0.809      0.864      0.422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/60      2.79G      1.868      0.993      1.017        140        640: 100% ━━━━━━━━━━━━ 16/16 3.9it/s 4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.1it/s 0.6s\n",
      "                   all         99        110      0.809      0.745      0.794      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/60       2.8G      1.938      1.003      1.029        147        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.0it/s 0.6s\n",
      "                   all         99        110      0.796      0.781      0.823      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/60      2.82G      1.873     0.9839      1.032        158        640: 100% ━━━━━━━━━━━━ 16/16 3.9it/s 4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.7it/s 0.5s\n",
      "                   all         99        110      0.808      0.809      0.865      0.447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/60      2.84G      1.862     0.9936      1.046        106        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.9it/s 0.6s\n",
      "                   all         99        110      0.904      0.768      0.826      0.373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/60      2.85G       1.91     0.9722      1.031        117        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.3it/s 0.8s\n",
      "                   all         99        110      0.847      0.827      0.862       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/60      2.87G      1.888     0.9729      1.036        104        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.0it/s 0.6s\n",
      "                   all         99        110      0.799      0.755      0.794      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/60      2.89G       1.89     0.9771      1.025        179        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.2it/s 0.6s\n",
      "                   all         99        110      0.875      0.831      0.878      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/60       2.9G      1.859     0.9731      1.034        172        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.5it/s 0.6s\n",
      "                   all         99        110      0.869      0.848      0.898      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/60      2.92G      1.822     0.9529      1.017        145        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.1it/s 0.6s\n",
      "                   all         99        110      0.849      0.816      0.852      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/60      2.94G      1.856     0.9663      1.011        174        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.5it/s 0.5s\n",
      "                   all         99        110      0.831      0.873      0.897      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/60      2.96G      1.814     0.9139      1.015        121        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.8it/s 0.6s\n",
      "                   all         99        110       0.86        0.8      0.856      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/60      2.97G      1.774     0.9106      1.001        144        640: 100% ━━━━━━━━━━━━ 16/16 4.0it/s 4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.2it/s 0.6s\n",
      "                   all         99        110      0.888      0.818       0.87      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/60      2.99G      1.823     0.9344      1.004        100        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.6it/s 0.6s\n",
      "                   all         99        110      0.856       0.81      0.876      0.423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/60      3.01G      1.841     0.9312      1.017        143        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.3it/s 0.5s\n",
      "                   all         99        110      0.945      0.782      0.865      0.438\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/60      3.02G       1.85     0.9325      1.028        110        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.7it/s 0.6s\n",
      "                   all         99        110      0.874      0.817       0.86      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/60      3.04G      1.805     0.9006      1.006        157        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.8it/s 0.6s\n",
      "                   all         99        110      0.926      0.799      0.877      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/60      3.06G      1.781     0.8973      1.022         90        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.2it/s 0.6s\n",
      "                   all         99        110       0.91      0.824      0.889      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/60      3.08G      1.766     0.8842     0.9995        212        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.8it/s 0.6s\n",
      "                   all         99        110      0.867      0.836      0.888      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/60      3.09G      1.798     0.9008      1.013        102        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.6it/s 0.6s\n",
      "                   all         99        110      0.886      0.845      0.886      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/60      3.11G      1.775     0.8789     0.9948        123        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.6it/s 0.7s\n",
      "                   all         99        110      0.837       0.84      0.874      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/60      3.13G      1.785     0.9153      1.006        163        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.0it/s 0.6s\n",
      "                   all         99        110       0.86      0.836      0.872      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/60      3.14G      1.768     0.8644     0.9998        211        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 5.8it/s 0.7s\n",
      "                   all         99        110      0.902      0.864      0.896      0.443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/60      3.16G      1.762       0.88     0.9909        105        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.7it/s 0.6s\n",
      "                   all         99        110      0.868      0.839      0.894      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/60      3.18G      1.758     0.8748      0.994        139        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.7it/s 0.6s\n",
      "                   all         99        110       0.89       0.88      0.907      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/60       3.2G      1.744     0.8568     0.9856        173        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.3it/s 0.5s\n",
      "                   all         99        110      0.883      0.823      0.875      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/60      3.21G      1.764     0.8703      1.004        135        640: 100% ━━━━━━━━━━━━ 16/16 4.0it/s 4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.1it/s 0.6s\n",
      "                   all         99        110      0.878      0.818      0.889      0.451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/60      3.23G      1.797     0.9009          1        162        640: 100% ━━━━━━━━━━━━ 16/16 4.1it/s 3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.4it/s 0.5s\n",
      "                   all         99        110      0.868       0.84      0.895      0.459\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      51/60      3.25G      1.723     0.8375      1.032         86        640: 100% ━━━━━━━━━━━━ 16/16 3.0it/s 5.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.7it/s 0.6s\n",
      "                   all         99        110      0.896      0.855      0.891      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      52/60      3.26G      1.707     0.8356      1.014         87        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.0it/s 0.6s\n",
      "                   all         99        110      0.884      0.831      0.876      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      53/60      3.28G        1.7     0.8134       1.02         96        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.4it/s 0.5s\n",
      "                   all         99        110      0.892      0.827      0.884      0.445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      54/60       3.3G      1.688      0.817      1.028        137        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.7it/s 0.5s\n",
      "                   all         99        110      0.885      0.845      0.892      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      55/60      3.31G      1.724     0.8407      1.022        160        640: 100% ━━━━━━━━━━━━ 16/16 4.4it/s 3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.2it/s 0.6s\n",
      "                   all         99        110      0.895      0.857      0.907      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      56/60      3.33G      1.689     0.8097      1.016        118        640: 100% ━━━━━━━━━━━━ 16/16 4.3it/s 3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.7it/s 0.6s\n",
      "                   all         99        110      0.904      0.856      0.904       0.44\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      57/60      3.35G      1.677     0.8062      1.007        131        640: 100% ━━━━━━━━━━━━ 16/16 4.5it/s 3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.2it/s 0.6s\n",
      "                   all         99        110      0.894      0.848      0.892      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      58/60      3.37G      1.669     0.8042          1        135        640: 100% ━━━━━━━━━━━━ 16/16 4.4it/s 3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.0it/s 0.6s\n",
      "                   all         99        110      0.894      0.846      0.889      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      59/60      3.38G        1.7     0.8267      1.021         80        640: 100% ━━━━━━━━━━━━ 16/16 4.2it/s 3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 7.6it/s 0.5s\n",
      "                   all         99        110      0.895      0.852      0.897      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      60/60       3.4G      1.656     0.8097      1.008         97        640: 100% ━━━━━━━━━━━━ 16/16 4.5it/s 3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 6.6it/s 0.6s\n",
      "                   all         99        110      0.895      0.854      0.895      0.439\n",
      "\n",
      "60 epochs completed in 0.080 hours.\n",
      "Optimizer stripped from /kaggle/working/runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /kaggle/working/runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /kaggle/working/runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.200 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         99        110      0.885      0.839      0.878      0.452\n",
      "Speed: 0.3ms preprocess, 14.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/runs/detect/train\u001b[0m\n",
      "[fit] best model: /kaggle/working/runs/detect/train/weights/best.pt\n",
      "[tune-gate] base_collect=0.060 (min_cs=0.080)\n",
      "[tune-gate] precomputing boxes for 18 (iou,max_det) pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[boxes]: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.60it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.58it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.62it/s]\n",
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tune-gate] search combos: 500 (cap), full=5292\n",
      "[tune-gate] best: cs=0.160, cb=0.360, area_thr=0.0018, iou=0.45, max_det=300  RMSE=0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.57it/s]\n",
      "[feats]: 100%|██████████| 2/2 [00:01<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[calib] Ridge(residual) alpha=10.0  CV-RMSE(resid)=0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[boxes]: 100%|██████████| 2/2 [00:01<00:00,  1.63it/s]\n",
      "[feats]: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[val-count] plain: RMSE=0.348, MAE=0.121  |  calibrated: RMSE=0.334, MAE=0.151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/runs/detect/train/weights/best.pt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline = YOLODetectionPipeline(\n",
    "#     model_ckpt=\"yolov10n.pt\",\n",
    "#     image_col=\"image_path\",\n",
    "#     boxes_col=\"label\",\n",
    "#     enable_tuning=True,\n",
    "#     enable_ridge=True,\n",
    "#     validate_count=True,\n",
    "#     tune_val_subsample=None,  # вся валидация для подбора параметров для подсчёта объектов\n",
    "#     tune_max_combinations=100,  ######################### 50\n",
    "#     random_state=42,\n",
    "#     verbose=True\n",
    "# )\n",
    "# pipeline.fit(\n",
    "#     train_df=train_df,\n",
    "#     val_df=val_df,\n",
    "#     lr0=0.01,\n",
    "#     epochs=70,  ######################### 40\n",
    "#     imgsz=640,\n",
    "#     batch=32,\n",
    "#     iou=0.5,\n",
    "#     rect=True,\n",
    "#     device='0,1'\n",
    "# )\n",
    "\n",
    "# import random\n",
    "\n",
    "# # 1) Сетки, основанные на ваших перцентилях\n",
    "# AREA_THR_GRID = [0.0008, 0.0010, 0.0012, 0.0015]\n",
    "# CS_GRID = [0.10, 0.12, 0.14, 0.18]\n",
    "# CB_GRID = [0.30, 0.40, 0.50]\n",
    "# IOU_GRID = [0.55, 0.60]           # жёстче на разреженной вал\n",
    "# MAXDET_GRID = [300, 600]          # хватает при p95=6\n",
    "# RIDGE_ALPHA_GRID = [0.3, 1.0, 3.0]\n",
    "\n",
    "# def make_gate_candidates():\n",
    "#     cands = []\n",
    "#     for area_thr in AREA_THR_GRID:\n",
    "#         for cs in CS_GRID:\n",
    "#             base = max(0.03, cs - 0.03)\n",
    "#             for cb in CB_GRID:\n",
    "#                 for iou in IOU_GRID:\n",
    "#                     for md in MAXDET_GRID:\n",
    "#                         cands.append(dict(\n",
    "#                             area_thr=area_thr, cs=cs, cb=cb,\n",
    "#                             gate_conf_base=base,\n",
    "#                             iou=iou, max_det=md\n",
    "#                         ))\n",
    "#     random.Random(42).shuffle(cands)\n",
    "#     return cands\n",
    "\n",
    "# gate_cands = make_gate_candidates()[:96]  # ограничили до ~100\n",
    "\n",
    "# pipe = YOLODetectionPipeline(\n",
    "#     model_ckpt=\"yolov8n.pt\",\n",
    "#     image_col=\"image_path\",\n",
    "#     boxes_col=\"label\",\n",
    "#     class_names=[\"obj\"],\n",
    "#     verbose=True,\n",
    "#     use_symlinks=True,\n",
    "\n",
    "#     # режимы\n",
    "#     enable_tuning=True,\n",
    "#     enable_ridge=True,\n",
    "#     validate_count=True,\n",
    "#     enable_area_gate=True,\n",
    "#     enable_tta_flip=False,      # начнём без TTA\n",
    "\n",
    "#     # лимит на поиск\n",
    "#     tune_val_subsample=None,\n",
    "#     tune_max_combinations=len(gate_cands),\n",
    "\n",
    "#     # сетки для gate (plain отключаем на этом проходе)\n",
    "#     tune_conf_small_grid = sorted(set([c[\"cs\"] for c in gate_cands])),\n",
    "#     tune_conf_big_grid   = sorted(set([c[\"cb\"] for c in gate_cands])),\n",
    "#     tune_area_thr_grid   = sorted(set([c[\"area_thr\"] for c in gate_cands])),\n",
    "\n",
    "#     # фикс для plain (чтобы не участвовали в поиске)\n",
    "#     tune_conf_grid = (0.30,),   # заглушки\n",
    "#     tune_iou_grid  = tuple(sorted(set([c[\"iou\"] for c in gate_cands]))),\n",
    "#     tune_max_det_grid = tuple(sorted(set([c[\"max_det\"] for c in gate_cands]))),\n",
    "\n",
    "#     # базовый порог — внутри пайпа сделайте зависимость base от cs, если поддерживается;\n",
    "#     # если нет — установите один: близко к cs-0.03, например 0.07\n",
    "#     gate_conf_base = 0.07,\n",
    "\n",
    "#     # Ridge\n",
    "#     ridge_alpha_grid = RIDGE_ALPHA_GRID,\n",
    "\n",
    "#     # фич-пороги\n",
    "#     small_thr=0.0010,\n",
    "#     big_thr=0.003,\n",
    "\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "pipe = YOLODetectionPipeline(\n",
    "    model_ckpt=\"yolov8n.pt\",\n",
    "    image_col=\"image_path\",\n",
    "    boxes_col=\"label\",\n",
    "    class_names=[\"obj\"],\n",
    "    verbose=True,\n",
    "    use_symlinks=True,\n",
    "\n",
    "    enable_tuning=True,\n",
    "    enable_ridge=True,\n",
    "    validate_count=True,\n",
    "\n",
    "    enable_area_gate=True,\n",
    "    enable_tta_flip=False,\n",
    "\n",
    "    tune_val_subsample=None,\n",
    "    tune_max_combinations=500,\n",
    "\n",
    "    tune_conf_grid=(0.18, 0.21, 0.24, 0.27, 0.30, 0.33, 0.36, 0.39, 0.42),\n",
    "    tune_iou_grid=(0.4, 0.45, 0.50, 0.55, 0.60, 0.65),\n",
    "    tune_max_det_grid=(300, 600, 1000),\n",
    "    tune_conf_small_grid=(0.08, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20),\n",
    "    tune_conf_big_grid=(0.28, 0.32, 0.36, 0.40, 0.45, 0.50, 0.55),\n",
    "    tune_area_thr_grid=(0.0006, 0.0008, 0.0010, 0.0012, 0.0015, 0.0018),\n",
    "    ridge_alpha_grid=(0.1, 0.3, 0.6, 1.0, 2.0, 3.0, 5.0, 7.5, 10.0),\n",
    "\n",
    "    gate_conf_base=0.07,\n",
    "    small_thr=0.0010,\n",
    "    big_thr=0.003,\n",
    "\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe.fit(\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    epochs=60,\n",
    "    imgsz=640,\n",
    "    batch=32,\n",
    "    device='0,1',\n",
    "    workers=4,\n",
    "    lr0=0.01,\n",
    "    cos_lr=True,\n",
    "    rect=True,\n",
    "    iou=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5edb00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T04:44:58.464638Z",
     "iopub.status.busy": "2025-09-16T04:44:58.464123Z",
     "iopub.status.idle": "2025-09-16T04:45:14.626758Z",
     "shell.execute_reply": "2025-09-16T04:45:14.625900Z"
    },
    "papermill": {
     "duration": 16.229492,
     "end_time": "2025-09-16T04:45:14.628035",
     "exception": false,
     "start_time": "2025-09-16T04:44:58.398543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[boxes]: 100%|██████████| 7/7 [00:09<00:00,  1.32s/it]\n",
      "[feats]: 100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200520_194614_01_JPG.rf.608a8b0fb1ef6a00bc4d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200520_194657_01_JPG.rf.9d2f98d60b7d94055523...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200520_214839_01_JPG.rf.9b38fd8cf74453b18370...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200521_065125_01_JPG.rf.94e220a6ec114bcc6dca...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200521_085200_01_JPG.rf.bc31e4d44d1925899c4b...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20200521_165417_01_JPG.rf.8f9738ea14df1bf74a3f...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20200521_185451_01_JPG.rf.ce8bb474653d4a11503c...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20200521_195509_01_JPG.rf.6ee8bf041b3178e2174d...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20200522_055812_01_JPG.rf.792e8156e38c8c35ad3b...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20200522_075847_01_JPG.rf.ff82846fbe8a7d7fcfa5...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20200522_085904_01_JPG.rf.b2f0c7a4c8aab86dc10e...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20200522_095921_01_JPG.rf.bbeae67b46e0f19edb62...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20200522_130013_01_JPG.rf.18d2eae4c4aa1719c481...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20200522_140030_01_JPG.rf.d471e0f339f0501cdcfa...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20200522_150047_01_JPG.rf.1f370a731f2f81ed3bf8...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20200522_210230_01_JPG.rf.c959680dab12537332b3...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20200523_070532_01_JPG.rf.6a47183c5707d0acb8f1...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20200523_090607_01_JPG.rf.7deac819ae549a2ad52d...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20200523_100625_01_JPG.rf.82ee88c9941283bf8e4d...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20200523_110642_01_JPG.rf.17c940c1ca3857a07fa8...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename  num\n",
       "0   20200520_194614_01_JPG.rf.608a8b0fb1ef6a00bc4d...    0\n",
       "1   20200520_194657_01_JPG.rf.9d2f98d60b7d94055523...    1\n",
       "2   20200520_214839_01_JPG.rf.9b38fd8cf74453b18370...   30\n",
       "3   20200521_065125_01_JPG.rf.94e220a6ec114bcc6dca...   32\n",
       "4   20200521_085200_01_JPG.rf.bc31e4d44d1925899c4b...   32\n",
       "5   20200521_165417_01_JPG.rf.8f9738ea14df1bf74a3f...   25\n",
       "6   20200521_185451_01_JPG.rf.ce8bb474653d4a11503c...   22\n",
       "7   20200521_195509_01_JPG.rf.6ee8bf041b3178e2174d...   28\n",
       "8   20200522_055812_01_JPG.rf.792e8156e38c8c35ad3b...   23\n",
       "9   20200522_075847_01_JPG.rf.ff82846fbe8a7d7fcfa5...   24\n",
       "10  20200522_085904_01_JPG.rf.b2f0c7a4c8aab86dc10e...   28\n",
       "11  20200522_095921_01_JPG.rf.bbeae67b46e0f19edb62...   19\n",
       "12  20200522_130013_01_JPG.rf.18d2eae4c4aa1719c481...   21\n",
       "13  20200522_140030_01_JPG.rf.d471e0f339f0501cdcfa...   25\n",
       "14  20200522_150047_01_JPG.rf.1f370a731f2f81ed3bf8...   23\n",
       "15  20200522_210230_01_JPG.rf.c959680dab12537332b3...   33\n",
       "16  20200523_070532_01_JPG.rf.6a47183c5707d0acb8f1...   13\n",
       "17  20200523_090607_01_JPG.rf.7deac819ae549a2ad52d...   18\n",
       "18  20200523_100625_01_JPG.rf.82ee88c9941283bf8e4d...   21\n",
       "19  20200523_110642_01_JPG.rf.17c940c1ca3857a07fa8...    6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pipe.predict_counts(submission_data)['label']\n",
    "submission = submission_data.copy()\n",
    "submission = pd.DataFrame({\n",
    "    'filename': [path.replace(test_img, '') for path in submission_data['image_path']],\n",
    "    'num': [round(x) for x in preds]\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head(20)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8266418,
     "sourceId": 13054157,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 465.727589,
   "end_time": "2025-09-16T04:45:15.717944",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-16T04:37:29.990355",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
