{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightfm\n\nfrom lightfm.data import Dataset\nfrom lightfm import LightFM\nfrom scipy.sparse import coo_matrix\nfrom collections.abc import Iterable\nfrom tqdm.auto import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-09T11:55:14.546134Z","iopub.execute_input":"2025-07-09T11:55:14.546794Z","execution_failed":"2025-07-09T11:55:25.540Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting lightfm\n  Downloading lightfm-1.17.tar.gz (316 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.26.4)\nRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.15.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.32.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->lightfm) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2025.4.26)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->lightfm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->lightfm) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->lightfm) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->lightfm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->lightfm) (2024.2.0)\nBuilding wheels for collected packages: lightfm\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Pipeline для LightFM.","metadata":{}},{"cell_type":"code","source":"class HybridRecommender:\n    \"\"\"\n    Рекомендательная система, основанная на LightFM. Работает с implicit и explicit данными и\n    только с pd.DataFrame (pandas таблица).\n    \"\"\"\n\n    def __init__(self, no_components, user_id_column_name, \n                 item_id_column_name, rating_column_name=None,\n                 user_features_names=None, item_features_names=None):\n        \"\"\"\n        :param no_components: Количество компонент в LightFM.\n        :param user_id_column_name: Имя столбца в pd.DataFrame с id пользователя.\n        :param item_id_column_name: Имя столбца в pd.DataFrame с id item'а.\n        :param rating_column_name: Имя столбца в pd.DataFrame с рэйтингами item'ов.\n        :param user_features_names: Список с именами столбцов, содержащих признаки пользователей.\n        :param item_features_names: Список с именами столбцов, содержащих признаки item'ов.\n        \"\"\"\n\n        self.no_components = no_components\n        self.user_id_column_name = user_id_column_name\n        self.item_id_column_name = item_id_column_name\n        self.rating_column_name = rating_column_name\n        self.user_features_names = user_features_names or []\n        self.item_features_names = [col for col in (item_features_names or []) if col != rating_column_name]\n\n    def _build_features_matrix(self, data, feature_names, id_col, build_method):\n        \"\"\"Вспомогательный метод для создания разреженной матрицы признаков.\"\"\"\n\n        if not feature_names:\n            return None\n        \n        features_df = data.drop_duplicates(subset=[id_col])\n        feature_generator = (\n            (getattr(row, id_col), [f'{col}:{getattr(row, col)}' for col in feature_names if pd.notna(getattr(row, col))])\n            for row in features_df.itertuples()\n        )\n\n        return build_method(feature_generator)\n\n    def fit(self, train_data, submission_data=None, epochs=15, num_threads=4, verbose=True):\n        \"\"\"\n        Обучает модель на основе таблицы, где показаны взаимодействия пользователей и item'ов.\n        Может также использовать признаки пользователей и item'ов.\n\n        :param train_data: pd.DataFrame со столбцами id пользователей и id item'ов и, возможно, их признаками.\n        :param submission_data: (Опционально) pd.DataFrame, который будет использоваться для рекомендаций.\n                                 Полезен, чтобы LightFM \"узнал\" о пользователях из сабмита заранее.\n        :param epochs: Количество эпох для обучения модели.\n        :param num_threads: Количество потоков для распараллеливания обучения в LightFM.\n        :param verbose: Выводить ли информацию об обучении.\n        \"\"\"\n\n        train_data = self._preprocess_features(train_data)\n        if submission_data is not None:\n            submission_data = self._preprocess_features(submission_data)\n\n        all_user_features = {f'{col}:{val}' for col in self.user_features_names for val in train_data[col].dropna().unique()}\n        if submission_data is not None:\n            user_features_sub = {f'{col}:{val}' for col in self.user_features_names if col in submission_data\n                                 for val in submission_data[col].dropna().unique()}\n            all_user_features.update(user_features_sub)\n\n        all_item_features = {f'{col}:{val}' for col in self.item_features_names for val in train_data[col].dropna().unique()}\n        all_users = pd.concat([train_data[self.user_id_column_name], submission_data[self.user_id_column_name]],\n                              ignore_index=True).unique() if submission_data is not None else train_data[self.user_id_column_name].unique()\n\n        interactions_cols = [self.user_id_column_name, self.item_id_column_name]\n        if self.rating_column_name:\n            interactions_cols.append(self.rating_column_name)\n        interactions_data = train_data[interactions_cols].itertuples(index=False)\n\n        self.dataset = Dataset(); self.dataset.fit(users=all_users, items=train_data[self.item_id_column_name].unique(),\n                                                   user_features=all_user_features, item_features=all_item_features)\n        interactions, weights = self.dataset.build_interactions(interactions_data)\n\n        self.user_features_matrix = self._build_features_matrix(train_data, self.user_features_names, self.user_id_column_name,\n                                                                self.dataset.build_user_features)\n        self.item_features_matrix = self._build_features_matrix(train_data, self.item_features_names, self.item_id_column_name,\n                                                                self.dataset.build_item_features)\n\n        self.user_id_map, _, self.item_id_map, _ = self.dataset.mapping()\n        self.inv_item_map = {v: k for k, v in self.item_id_map.items()}\n\n        self.model = LightFM(loss='warp', no_components=self.no_components, random_state=42)\n        self.model.fit(interactions, sample_weight=weights, user_features=self.user_features_matrix,\n                       item_features=self.item_features_matrix, epochs=epochs, num_threads=num_threads, verbose=verbose)\n\n        self.users_items_interactions_dict = train_data.groupby(self.user_id_column_name)[self.item_id_column_name].apply(set).to_dict()\n        self.items_popularity = train_data[self.item_id_column_name].value_counts()\n        self.sorted_items_by_popularity = self.items_popularity.index.tolist()\n        self.all_item_ids = np.arange(interactions.shape[1], dtype=np.int32)\n\n        return self\n\n    def predict(self, df, n_recommendations, num_threads=4, return_scores=False, verbose=True):\n        \"\"\"\n        Даёт рекомендации для пользователей.\n        \n        :param df: pd.DataFrame с пользователями для предсказания.\n        :param n_recommendations: Количество рекомендаций для каждого пользователя.\n        :param num_threads: Количество потоков для распараллеливания прогнозов в LightFM.\n        :param return_scores: Если True, возвращает список кортежей (item_id, score). Иначе - только список item_id.\n        :param verbose: Выводить ли информацию о процессе.\n        :return: Словарь с рекомендациями {user_id: [rec_1, rec_2, ...]}.\n        \"\"\"\n\n        df = self._preprocess_features(df)\n        all_recommendations = {}\n\n        known_user_mask = df[self.user_id_column_name].isin(self.user_id_map)\n        known_user_ids_original = df.loc[known_user_mask, self.user_id_column_name].unique()\n        unknown_user_ids_original = df.loc[~known_user_mask, self.user_id_column_name].unique()\n\n        # обработка неизвестных пользователей\n        for user_id in unknown_user_ids_original:\n            top_popular = self.sorted_items_by_popularity[:n_recommendations]\n            if return_scores:\n                all_recommendations[user_id] = list(zip(top_popular, self.items_popularity.loc[top_popular].tolist()))\n            else:\n                all_recommendations[user_id] = top_popular\n        \n        # обработка известных пользователей\n        if len(known_user_ids_original) > 0:\n            n_items = len(self.all_item_ids)\n            iterator = tqdm(known_user_ids_original, desc='Генерация рекомендаций') if verbose else known_user_ids_original\n            \n            for user_id_orig in iterator:\n                user_id_int = self.user_id_map[user_id_orig]\n                user_id_repeated = np.full(n_items, user_id_int, dtype=np.int32)\n\n                scores = self.model.predict(user_id_repeated, self.all_item_ids, user_features=self.user_features_matrix,\n                                            item_features=self.item_features_matrix, num_threads=num_threads)\n\n                used_items = self.users_items_interactions_dict.get(user_id_orig, set())\n                if used_items:\n                    used_internal_ids = [self.item_id_map[item] for item in used_items if item in self.item_id_map]\n                    scores[used_internal_ids] = -np.inf\n\n                # остальная логика без изменений\n                top_items_internal = np.argsort(-scores)[:n_recommendations]\n                recs = [self.inv_item_map[i] for i in top_items_internal]\n\n                if return_scores:\n                    all_recommendations[user_id_orig] = list(zip(recs, scores[top_items_internal]))\n                else:\n                    all_recommendations[user_id_orig] = recs\n\n        return all_recommendations\n    \n    def convert_recommendations_dict_to_pandas(self, recommendations_dict):\n        \"\"\"\n        Конвертирует словарь с рекомендациями в pd.DataFrame (pandas таблицу).\n\n        :param recommendations_dict: Словарь с рекомендациями: {u1: [i1, i2, ...], u2: [i1, i2, ...], ...}.\n        :return: pd.DataFrame с рекомендациями.\n        \"\"\"\n\n        recommendations = []\n        for user_id, rec_list in recommendations_dict.items():\n            row = {self.user_id_column_name: user_id}\n            for i, item_id in enumerate(rec_list):\n                if isinstance(item_id, tuple): # Обработка случая, когда predict возвращает (item, score)\n                    item_id = item_id[0]\n                row[f'{self.item_id_column_name}_{i + 1}'] = item_id\n            recommendations.append(row)\n        return pd.DataFrame(recommendations)\n\n    def _preprocess_features(self, df):\n        \"\"\"\n        Быстро и корректно стандартизирует признаки в DataFrame. Числа без дробной части приводятся к строке\n        без \".0\". Это нужно для того, чтобы LightFM не считал признаки \"12\" и \"12.0\" разными.\n        \"\"\"\n\n        df_copy = df.copy()\n        feature_cols = set(self.user_features_names + self.item_features_names) & set(df_copy.columns)\n        \n        for col in feature_cols:\n            df_copy[col] = df_copy[col].astype(str)\n            s_numeric = pd.to_numeric(df_copy[col], errors='coerce')\n            is_integer_mask = pd.notna(s_numeric) & (s_numeric == np.floor(s_numeric))\n            \n            if is_integer_mask.any():\n                df_copy.loc[is_integer_mask, col] = s_numeric[is_integer_mask].astype(int).astype(str)\n                \n        return df_copy","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-09T11:55:25.541Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Пример использования с implicit данными:","metadata":{}},{"cell_type":"code","source":"# создание данных\ntrain_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_1', 'user_2', 'user_2', 'user_3'],\n    'community_id': ['item_A', 'item_B', 'item_C', 'item_D', 'item_A']\n})\nsubmission_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_3', 'user_4']\n})\n\nmodel = HybridRecommender(no_components=4, user_id_column_name='customer_id', item_id_column_name='community_id')  # создание модели\nmodel.fit(train_data, epochs=5)  # обучение модели\nrecommendations_dict = model.predict(submission_data, n_recommendations=3, return_scores=True)  # рекомендация item'ов пользователям\n\nsubmission_df = model.convert_recommendations_dict_to_pandas(recommendations_dict)  # из словаря в pandas таблицу\nsubmission_df.head()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-09T11:55:25.541Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Пример использования с explicit данными:","metadata":{}},{"cell_type":"code","source":"# создание данных\ntrain_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_1', 'user_2', 'user_2', 'user_3'],\n    'customer_age': [12, 12, 22, 22, 17],\n    'customer_city': ['Moscow', 'Moscow', 'Ekaterinburg', 'Ekaterinburg', 'Arkhangelsk'],\n\n    'community_id': ['item_A', 'item_B', 'item_C', 'item_D', 'item_A'],\n    'community_type': ['games', 'education', 'education', 'business', 'games'],\n    'community_rating': [3, 4, 4, 5, 3]\n})\nsubmission_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_3', 'user_4'],\n    'customer_age': [12, 17, 122.449],\n    # здесь недостаёт признака 'customer_city', но HybridRecommender всё равно правильно его обработал\n})\n\n# создание и обучение модели\nmodel = HybridRecommender(\n    no_components=4,\n    user_id_column_name='customer_id',\n    item_id_column_name='community_id',\n    rating_column_name='community_rating',\n    user_features_names=['customer_age', 'customer_city'],\n    item_features_names=['community_type']\n\n)\nmodel.fit(train_data, submission_data, epochs=5)\n\nrecommendations_dict = model.predict(submission_data, n_recommendations=3, return_scores=True)  # рекомендация item'ов пользователям\n\nsubmission_df = model.convert_recommendations_dict_to_pandas(recommendations_dict)  # из словаря в pandas таблицу\nsubmission_df.head()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-09T11:55:25.541Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pipeline для Two-Stage RecSys, основанная на LightFM и мощном классификаторе.","metadata":{}},{"cell_type":"markdown","source":"**Инициализируйте HybridRecommender выше.**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-09T11:55:25.541Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Пример использования на explicit данных.","metadata":{}},{"cell_type":"markdown","source":"Пример 1:","metadata":{}},{"cell_type":"code","source":"class TwoStageRecommender:\n    \"\"\"\n    Двухэтапная рекомендательная система с автоматическим созданием признаков для ранжировщика.\n    \"\"\"\n\n    def __init__(self, candidate_generator, ranker, user_id_column_name,\n                 item_id_column_name, ranker_feature_names=None):\n        \"\"\"\n        :param candidate_generator: Объект-генератор кандидатов (например, HybridRecommender).\n        :param ranker: Классификатор с scikit-learn API (например, CatBoostClassifier).\n        :param user_id_column_name: Имя столбца с ID пользователя.\n        :param item_id_column_name: Имя столбца с ID айтема.\n        :param ranker_feature_names: (Опционально) Список ИСХОДНЫХ имен столбцов-признаков.\n        \"\"\"\n        self.candidate_generator = candidate_generator\n        self.ranker = ranker\n        self.user_id_column_name = user_id_column_name\n        self.item_id_column_name = item_id_column_name\n        self.initial_ranker_features = ranker_feature_names or []\n        # хранилища для данных и признаков\n        self._full_feature_data = None\n        self._features_cache = None\n        self._user_stats_df = None\n        self._item_stats_df = None\n        self._final_ranker_features = []\n\n    def fit(self, train_data, submission_data=None, ranker_train_size=0.5,\n            n_candidates_for_ranker=100, ranker_validation_split_size=0.2, ranker_fit_batch_size=16,\n            generator_fit_params=None, ranker_fit_params=None):\n        \"\"\"\n        Обучает весь пайплайн: сначала генератор кандидатов, затем ранжировщик.\n        Устраняет утечку данных, разделяя train_data на две части.\n\n        :param train_data: pd.DataFrame с обучающими взаимодействиями.\n        :param submission_data: (Опционально) pd.DataFrame с пользователями для предсказания.\n        :param ranker_train_size: Доля данных для обучения ранжировщика (от 0 до 1).\n        :param n_candidates_for_ranker: Сколько кандидатов генерировать для обучения ранжировщика.\n        :param ranker_validation_split_size: Доля данных для валидации ранжировщика.\n        :param ranker_fit_batch_size: Размер батча для обучения ранжировщика.\n        :param generator_fit_params: Словарь с параметрами для .fit() генератора.\n        :param ranker_fit_params: Словарь с параметрами для .fit() ранжировщика.\n        \"\"\"\n        generator_fit_params = generator_fit_params or {}\n        ranker_fit_params = ranker_fit_params or {}\n        \n        # сохраняем все данные, содержащие признаки\n        data_parts = [train_data]\n        if submission_data is not None:\n            data_parts.append(submission_data)\n        self._full_feature_data = pd.concat(data_parts, ignore_index=True)\n\n        # разделяем данные для устранения утечки\n        generator_train_data, ranker_train_data = train_test_split(\n            train_data, test_size=ranker_train_size, random_state=42\n        )\n        print(f\"Данные разделены: {len(generator_train_data)} строк для генератора, {len(ranker_train_data)} для ранжировщика.\")\n\n        # --- Этап 1: Обучение генератора кандидатов ---\n        print(\"\\n--- Этап 1: Обучение генератора кандидатов ---\")\n        self.candidate_generator.fit(generator_train_data, submission_data, **generator_fit_params)\n\n        # --- Этап 2: Обучение ранжировщика ---\n        print(\"\\n--- Этап 2: Обучение ранжировщика ---\")\n        self._fit_ranker(ranker_train_data, n_candidates_for_ranker, ranker_validation_split_size,\n                         ranker_fit_params, batch_size=ranker_fit_batch_size)\n        \n        return self\n\n    def _fit_ranker(self, ranker_train_data, n_candidates, val_size, fit_params, batch_size=256):\n        \"\"\"Внутренний метод для подготовки данных и обучения ранжировщика.\"\"\"\n\n        # генерация статистических признаков (без изменений)\n        self._item_stats_df = ranker_train_data.groupby(self.item_id_column_name).agg(item_popularity=(\n            self.user_id_column_name, 'count'), item_n_unique_users=(self.user_id_column_name, 'nunique')).reset_index()\n        self._user_stats_df = ranker_train_data.groupby(self.user_id_column_name).agg(user_activity=(\n            self.item_id_column_name, 'count'), user_n_unique_items=(self.item_id_column_name, 'nunique')).reset_index()\n        generated = ['item_popularity', 'item_n_unique_users', 'user_activity', 'user_n_unique_items', 'generator_score']\n        self._final_ranker_features = self.initial_ranker_features + generated\n\n        all_users_for_ranker = ranker_train_data[self.user_id_column_name].unique()\n        positives_set = set(zip(ranker_train_data[self.user_id_column_name], ranker_train_data[self.item_id_column_name]))\n\n        dataset_batches = []\n        # итерация по батчам пользователей\n        for i in tqdm(range(0, len(all_users_for_ranker), batch_size), desc=\"Создание датасета для ранжировщика\"):\n            user_batch = all_users_for_ranker[i : i + batch_size]\n            users_df_batch = pd.DataFrame(user_batch, columns=[self.user_id_column_name])\n\n            # генерация кандидатов только для батча\n            candidates_dict_batch = self.candidate_generator.predict(users_df_batch, n_recommendations=n_candidates,\n                                                                     return_scores=True, verbose=False)\n            if not any(candidates_dict_batch.values()): continue\n\n            # создание временного списка с данными для DataFrame\n            dataset_list_batch = [{\n                self.user_id_column_name: uid, self.item_id_column_name: iid, 'generator_score': score,\n                'target': 1 if (uid, iid) in positives_set else 0\n            } for uid, items in candidates_dict_batch.items() for iid, score in items]\n\n            if dataset_list_batch: dataset_batches.append(pd.DataFrame(dataset_list_batch))\n\n        # сборка итогового датасета из всех батчей\n        ranker_dataset = pd.concat(dataset_batches, ignore_index=True)\n        del dataset_batches # освобождаем память\n\n        # разделение и обучение (логика остается прежней)\n        train_df, val_df = train_test_split(ranker_dataset, test_size=val_size, random_state=42, stratify=ranker_dataset['target'])\n        print(\"Обогащение данных признаками и обучение модели...\")\n        x_train, y_train = self._prepare_ranker_features(train_df), train_df['target']\n        x_val, y_val = self._prepare_ranker_features(val_df), val_df['target']\n\n        if 'eval_set' not in fit_params:\n            if 'catboost' in self.ranker.__class__.__name__.lower():\n                fit_params['eval_set'] = (x_val, y_val) \n            else:\n                fit_params['eval_set'] = [(x_val, y_val)]\n\n        self.ranker.fit(x_train, y_train, **fit_params)\n    \n    def predict(self, df, n_candidates, n_recommendations, batch_size=256, verbose=True):\n        \"\"\"\n        Генерирует финальные рекомендации для пользователей в два этапа.\n\n        :param df: pd.DataFrame с пользователями для предсказания.\n        :param n_candidates: Количество кандидатов для генерации на 1-м этапе.\n        :param n_recommendations: Итоговое количество рекомендаций.\n        :param batch_size: Размер батча.\n        :param verbose: Выводить ли информацию о процессе.\n        :return: Словарь с финальными рекомендациями {user_id: [rec_1, rec_2, ...]}.\n        \"\"\"\n\n        all_users = df[self.user_id_column_name].unique()\n        final_recs_dict = {}\n\n        # итерация по батчам пользователей\n        for i in tqdm(range(0, len(all_users), batch_size), desc=\"Финальные рекомендации\"):\n            user_batch = all_users[i : i + batch_size]\n            df_batch = pd.DataFrame(user_batch, columns=[self.user_id_column_name])\n\n            # генерация кандидатов для батча\n            candidates_dict = self.candidate_generator.predict(df_batch, n_recommendations=n_candidates, return_scores=True, verbose=False)\n            if not any(candidates_dict.values()):\n                for user_id in user_batch: final_recs_dict[user_id] = []\n                continue\n\n            # создание DataFrame из кандидатов батча\n            candidates_list = [{self.user_id_column_name: uid, self.item_id_column_name: iid, 'generator_score': score}\n                               for uid, items in candidates_dict.items() for iid, score in items]\n            candidates_df = pd.DataFrame(candidates_list)\n\n            # предсказания и ранжирование для батча\n            X_pred = self._prepare_ranker_features(candidates_df)\n            candidates_df['ranker_score'] = self.ranker.predict_proba(X_pred)[:, 1]\n            candidates_df = candidates_df.sort_values('ranker_score', ascending=False)\n            top_ranked_df = candidates_df.groupby(self.user_id_column_name).head(n_recommendations)\n\n            # обновление итогового словаря рекомендаций\n            batch_recs_dict = top_ranked_df.groupby(self.user_id_column_name)[self.item_id_column_name].apply(list).to_dict()\n            final_recs_dict.update(batch_recs_dict)\n\n        # убеждаемся, что все пользователи из исходного запроса есть в ответе\n        return {user_id: final_recs_dict.get(user_id, []) for user_id in df[self.user_id_column_name].unique()}\n\n    def _prepare_ranker_features(self, df):\n        \"\"\"Внутренний метод для обогащения датафрейма признаками перед ранжированием.\"\"\"\n\n        df_with_features = df.copy()\n        \n        # присоединяем исходные признаки, если они были указаны\n        if self.initial_ranker_features:\n            if self._features_cache is None:\n                # кэшируем признаки, чтобы не делать это много раз\n                cols_to_cache = [self.user_id_column_name] + [c for c in self.initial_ranker_features if c in self._full_feature_data.columns]\n                self._features_cache = self._full_feature_data[list(set(cols_to_cache))].drop_duplicates(subset=[self.user_id_column_name])\n            \n            df_with_features = df_with_features.merge(self._features_cache, on=self.user_id_column_name, how='left')\n\n        # присоединяем статистические признаки\n        df_with_features = df_with_features.merge(self._user_stats_df, on=self.user_id_column_name, how='left')\n        df_with_features = df_with_features.merge(self._item_stats_df, on=self.item_id_column_name, how='left')\n        \n        # выбираем финальный набор признаков\n        final_cols = [col for col in self._final_ranker_features if col in df_with_features.columns]\n        df_final = df_with_features[final_cols].copy()\n        \n        # обрабатываем пропуски в зависимости от типа колонки\n        for col in df_final.columns:\n            if pd.api.types.is_numeric_dtype(df_final[col]):\n                df_final[col] = df_final[col].fillna(0)\n            else:\n                df_final[col] = df_final[col].fillna('[MISSING]')\n        \n        return df_final\n    \n    def convert_recommendations_dict_to_pandas(self, recommendations_dict):\n        \"\"\"\n        Конвертирует словарь с рекомендациями в pd.DataFrame (pandas таблицу).\n\n        :param recommendations_dict: Словарь с рекомендациями: {u1: [i1, i2, ...], u2: [i1, i2, ...], ...}.\n        :return: pd.DataFrame с рекомендациями.\n        \"\"\"\n\n        return self.candidate_generator.convert_recommendations_dict_to_pandas(recommendations_dict)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-09T11:55:25.541Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# создание данных\ntrain_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_1', 'user_2', 'user_2', 'user_3', 'user_1', 'user_3', 'user_4', 'user_4', 'user_2', 'user_3'],\n    'customer_age': [25, 25, 30, 30, 22, 25, 22, 45, 45, 30, 22],\n    'customer_sex': ['M', 'M', 'F', 'F', 'M', 'M', 'M', 'F', 'F', 'F', 'M'],\n    'community_id': ['item_A', 'item_B', 'item_C', 'item_D', 'item_A', 'item_E', 'item_C', 'item_B', 'item_D', 'item_F', 'item_F'],\n    'community_type': ['games', 'edu', 'edu', 'business', 'games', 'travel', 'edu', 'edu', 'business', 'music', 'music'],\n})\nsubmission_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_2', 'user_5'],\n    'customer_age': [25, 30, 50],\n    'customer_sex': ['M', 'F', 'M'],\n})\n\n# создание компонентов\ncandidate_generator = HybridRecommender(\n    no_components=15,\n    user_id_column_name='customer_id',\n    item_id_column_name='community_id'\n    \n)\nranker = CatBoostClassifier(\n    n_estimators=1000,\n    depth=4,\n    learning_rate=0.03,\n    auto_class_weights='Balanced',\n    eval_metric='AUC',\n    early_stopping_rounds=300,\n    random_state=42,\n    verbose=100\n)\n\n# создание двухэтапной модели\npipeline = TwoStageRecommender(\n    candidate_generator=candidate_generator,\n    ranker=ranker,\n    user_id_column_name='customer_id',\n    item_id_column_name='community_id'\n)\n\n# обучение генератора кандидатов\npipeline.fit(\n    train_data=train_data,  # train_data\n    submission_data=submission_data,\n    ranker_train_size=0.5,\n    n_candidates_for_ranker=100,\n    ranker_validation_split_size=0.2,\n    generator_fit_params={'epochs': 15, 'verbose': True},\n    ranker_fit_params=None\n)\n\n# получение рекомендаций для сабмита\nrecommendations_dict = pipeline.predict(\n    df=submission_data,\n    n_candidates=100,\n    n_recommendations=7,\n)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Пример 2:","metadata":{}},{"cell_type":"code","source":"# создание данных\ntrain_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_1', 'user_2', 'user_2', 'user_3', 'user_1', 'user_3', 'user_4', 'user_4', 'user_2', 'user_3'],\n    'customer_age': [25, 25, 30, 30, 22, 25, 22, 45, 45, 30, 22],\n    'customer_sex': ['M', 'M', 'F', 'F', 'M', 'M', 'M', 'F', 'F', 'F', 'M'],\n    'community_id': ['item_A', 'item_B', 'item_C', 'item_D', 'item_A', 'item_E', 'item_C', 'item_B', 'item_D', 'item_F', 'item_F'],\n    'community_type': ['games', 'edu', 'edu', 'business', 'games', 'travel', 'edu', 'edu', 'business', 'music', 'music'],\n})\nsubmission_data = pd.DataFrame({\n    'customer_id': ['user_1', 'user_2', 'user_5'],\n    'customer_age': [25, 30, 50],\n    'customer_sex': ['M', 'F', 'M'],\n})\n\n# создание компонентов\ncandidate_generator = HybridRecommender(\n    no_components=15,\n    user_id_column_name='customer_id',\n    item_id_column_name='community_id',\n    user_features_names=['customer_age', 'customer_sex'],\n    item_features_names=['community_type']\n)\nranker = CatBoostClassifier(\n    n_estimators=1000,\n    depth=4,\n    learning_rate=0.03,\n    auto_class_weights='Balanced',\n    cat_features=['customer_sex', 'community_type'],\n    eval_metric='AUC',\n    early_stopping_rounds=300,\n    random_state=42,\n    verbose=100\n)\nranker_features = ['customer_age', 'customer_sex', 'community_type']\n\n# создание двухэтапной модели\npipeline = TwoStageRecommender(\n    candidate_generator=candidate_generator,\n    ranker=ranker,\n    user_id_column_name='customer_id',\n    item_id_column_name='community_id',\n    ranker_feature_names=ranker_features\n)\n\n# обучение генератора кандидатов\npipeline.fit(\n    train_data=train_data,  # train_data\n    submission_data=submission_data,\n    ranker_train_size=0.5,\n    n_candidates_for_ranker=100,\n    ranker_validation_split_size=0.2,\n    generator_fit_params={'epochs': 15, 'verbose': True},\n    ranker_fit_params=None\n)\n\n# получение рекомендаций для сабмита\nrecommendations_dict = pipeline.predict(\n    df=submission_data,\n    n_candidates=100,\n    n_recommendations=7,\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-09T11:55:25.541Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}