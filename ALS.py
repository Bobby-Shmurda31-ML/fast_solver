import numpy as np
import pandas as pd
import scipy.sparse as sp
from implicit.als import ALS

# ===== 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• =====
# –ü—Ä–∏–º–µ—Ä: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ —Å–º–æ—Ç—Ä—è—Ç —Ñ–∏–ª—å–º—ã
data = pd.DataFrame({
    'user_id': [0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 3],
    'item_id': [0, 1, 2, 1, 3, 4, 0, 2, 1, 2, 4],
    'rating':  [5, 3, 4, 4, 5, 2, 5, 3, 4, 5, 3]
})

n_users = data['user_id'].max() + 1
n_items = data['item_id'].max() + 1

# –°–æ–∑–¥–∞–µ–º UI –º–∞—Ç—Ä–∏—Ü—É (user √ó item)
user_item = sp.csr_matrix(
    (data['rating'], (data['user_id'], data['item_id'])),
    shape=(n_users, n_items)
)

# –¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º –¥–ª—è fit() - –ø–æ–ª—É—á–∞–µ–º IU –º–∞—Ç—Ä–∏—Ü—É (item √ó user)
item_user = user_item.T.tocsr()

print(f"–ú–∞—Ç—Ä–∏—Ü–∞ user_item: {user_item.shape}")  # (4, 5)
print(f"–ú–∞—Ç—Ä–∏—Ü–∞ item_user: {item_user.shape}")  # (5, 4)

# ===== 2. –°–û–ó–î–ê–ù–ò–ï –ò –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò =====
model = ALS(
    factors=32,              # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
    regularization=0.01,     # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    iterations=20,           # –ß–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
    calculate_training_loss=True,
    random_state=42
)

# –û–±—É—á–µ–Ω–∏–µ –Ω–∞ IU –º–∞—Ç—Ä–∏—Ü–µ
model.fit(item_user, show_progress=True)

# ===== 3. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø =====
user_id = 0

# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
recommendations = model.recommend(
    userid=user_id,
    user_items=user_item[user_id],  # UI —Ñ–æ—Ä–º–∞—Ç!
    N=3,
    filter_already_liked_items=True
)

# –†–µ–∑—É–ª—å—Ç–∞—Ç: (item_ids, scores)
items, scores = recommendations
print(f"\nüì∫ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}:")
for item, score in zip(items, scores):
    print(f"  –§–∏–ª—å–º {item}: score = {score:.4f}")

# ===== 4. –ü–û–•–û–ñ–ò–ï –¢–û–í–ê–†–´ =====
item_id = 1

similar = model.similar_items(itemid=item_id, N=3)
items_sim, scores_sim = similar

print(f"\nüé¨ –§–∏–ª—å–º—ã –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ {item_id}:")
for item, score in zip(items_sim, scores_sim):
    print(f"  –§–∏–ª—å–º {item}: similarity = {score:.4f}")

# ===== 5. –ü–û–•–û–ñ–ò–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ò =====
similar_users = model.similar_users(userid=user_id, N=2)
users_sim, scores_sim = similar_users

print(f"\nüë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ {user_id}:")
for user, score in zip(users_sim, scores_sim):
    print(f"  User {user}: similarity = {score:.4f}")

# ===== 6. –û–ë–™–Ø–°–ù–ï–ù–ò–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò =====
# –ü–æ—á–µ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º item=3 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é user=0?
explanation = model.explain(
    userid=user_id,
    user_items=user_item[user_id],
    itemid=3,
    N=2
)
items_exp, scores_exp = explanation

print(f"\nüí° –ü–æ—á–µ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Ñ–∏–ª—å–º 3 –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}:")
for item, score in zip(items_exp, scores_exp):
    print(f"  –ü–æ—Ç–æ–º—É —á—Ç–æ —Å–º–æ—Ç—Ä–µ–ª —Ñ–∏–ª—å–º {item}: –≤–∫–ª–∞–¥ = {score:.4f}")

# ===== 7. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –†–ï–ô–¢–ò–ù–ì–ê =====
# –°–∫–æ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞—Ä—ã user-item
user_vector = model.user_factors[0]
item_vector = model.item_factors[3]
predicted_score = np.dot(user_vector, item_vector)

print(f"\n‚≠ê –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ (user 0, item 3): {predicted_score:.4f}")

# ===== 8. –†–ê–ë–û–¢–ê –° –§–ê–ö–¢–û–†–ê–ú–ò =====
print(f"\nüìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:")
print(f"  User —Ñ–∞–∫—Ç–æ—Ä—ã: {model.user_factors.shape}")  # (4, 32)
print(f"  Item —Ñ–∞–∫—Ç–æ—Ä—ã: {model.item_factors.shape}")  # (5, 32)

# –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 0
print(f"\n  User 0 —ç–º–±–µ–¥–¥–∏–Ω–≥ (–ø–µ—Ä–≤—ã–µ 5): {user_vector[:5]}")

# ===== 9. –ë–ê–¢–ß –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –í–°–ï–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô =====
all_recommendations = model.recommend(
    userid=np.arange(n_users),  # –í—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
    user_items=user_item,       # –í—Å—è –º–∞—Ç—Ä–∏—Ü–∞
    N=3
)

print(f"\nüéØ –¢–æ–ø-3 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:")
for uid, (items, scores) in enumerate(zip(*all_recommendations)):
    print(f"  User {uid}: items {items} (scores: {scores})")

# ===== 10. –•–û–õ–û–î–ù–´–ô –°–¢–ê–†–¢ - –ù–û–í–´–ô –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨ =====
# –ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ—Å–º–æ—Ç—Ä–µ–ª —Ñ–∏–ª—å–º—ã 0 –∏ 2
new_user_interactions = sp.csr_matrix(
    ([4, 5], ([0, 0], [0, 2])),  # —Ä–µ–π—Ç–∏–Ω–≥–∏ 4 –∏ 5
    shape=(1, n_items)
)

new_user_recs = model.recommend(
    userid=0,  # –õ—é–±–æ–π ID (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
    user_items=new_user_interactions[0],
    N=3,
    recalculate_user=True  # –í–ê–ñ–ù–û! –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã
)

print(f"\nüÜï –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:")
for item, score in zip(*new_user_recs):
    print(f"  –§–∏–ª—å–º {item}: score = {score:.4f}")

# ===== 11. –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê =====
from implicit.evaluation import train_test_split, precision_at_k, ndcg_at_k

# –†–∞–∑–±–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
train, test = train_test_split(user_item, train_percentage=0.8)

# –û–±—É—á–∞–µ–º –Ω–∞ train
train_item_user = train.T.tocsr()
model_eval = ALS(factors=32, iterations=15, random_state=42)
model_eval.fit(train_item_user, show_progress=False)

# –ú–µ—Ç—Ä–∏–∫–∏
p_at_5 = precision_at_k(model_eval, train, test, K=5)
ndcg = ndcg_at_k(model_eval, train, test, K=5)

print(f"\nüìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
print(f"  Precision@5: {p_at_5:.4f}")
print(f"  NDCG@5: {ndcg:.4f}")

# ===== 12. –°–û–•–†–ê–ù–ï–ù–ò–ï/–ó–ê–ì–†–£–ó–ö–ê =====
import pickle

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
with open('als_model.pkl', 'wb') as f:
    pickle.dump(model, f)

# –ó–∞–≥—Ä—É–∑–∫–∞
with open('als_model.pkl', 'rb') as f:
    loaded_model = pickle.load(f)

# –ü—Ä–æ–≤–µ—Ä–∫–∞
test_recs = loaded_model.recommend(0, user_item[0], N=3)
print(f"\nüíæ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏: {test_recs[0]}")
